---
title: Ingest your own data
sidebar_label: Ingest
path: basics/tutorials/ingest/ingest
nb_path: basics/tutorials/ingest.ipynb
github: 
  https://github.com/fusedio/fused-docs/blob/main/docs/basics/tutorials/ingest.ipynb
colab: 
  https://githubtocolab.com/fusedio/fused-docs/blob/main/docs/basics/tutorials/ingest.ipynb
description: Tutorial on how to ingest parquet data with Fused.
sidebar_position: 4
---

import LinkButtons from "@site/src/components/LinkButtons.jsx";
import CellOutput from "@site/src/components/CellOutput.jsx";
import {BokehFigure, PlotlyFigure} from "@site/src/components/Plotting.jsx";
import Tag from '@site/src/components/Tag'

## <Tag color="#D1E550" fontColor="#141414" >ðŸš§ Under Construction</Tag>


This guide shows how to use Fused to ingest data into an S3 bucket.

Note: steps in this notebook require authentication to Fused.

## Ingest data

Fused delivers speed advantages thanks to spatial partitioning. Geospatial operations
between two or more datasets are usually for spatially overlapping or neighboring areas
\- and usually for localized areas of interest. Breaking down datasets across geographic
chunks loads only the relevant data for each operation.

The [`fused.ingest()`](/python-sdk/top-level-functions/#ingest) method first uploads
data into an S3 bucket using [fused.upload](/python-sdk/top-level-functions/#upload) and
automatically geo partitions it.

:::warning

At the moment, Fused won't let you ingest multiple local files simultaneously. To ingest
multiple local files, first upload them with
[fused.upload](/python-sdk/top-level-functions/#upload) then specify an array of their
S3 paths as the input to ingest.

This is because Fused performs a lazy check to prevent scenarios where long uploads end
up failing due to a single file.

:::

Datasets ingested with Fused are spatially partitioned collections of Parquet files.
Each file has one or more chunks, which are a further level of spatial partitioning.

Columns in a dataset are grouped into tables. An ingested dataset contains a `main`
table with the original input columns and a `fused` table containing spatial metadata.

The `ingest()` method has many configuration options, which the API documentation
explains. The following sections cover a few different ingestion use cases.

:::info

If you encounter the message
`HTTPError: {'detail': 'Quota limit: Number of running instances'}`, please get in touch
with the Fused team to increase the number of workers allocated to your account.

:::

Pro tip: While Fused is generally used to ingest files, it's also possible to pass the
`GeoDataFrame` directly to `fused.ingest()`.

### Default ingestion

By default ingestion tries to create a certain number of files (`target_num_files=20`).
The number of rows per file and chunk are chosen to meet this target. Note that 20 files
is only a target and the actual number of files generated can vary.

```python
# !pip install fused -q
```

```python
import fused

job = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    output=f"fd://census/dc_tract",
)
job_id = job.run_remote()
```

While the job is running, follow its logs.

```python
job_id.tail_logs()
```

### Ingest multiple files

```python
import fused

job = fused.ingest(
    input=["s3://my-bucket/file1.parquet", "s3://my-bucket/file2.parquet"],
    output=f"fd://census/dc_tract",
)
job_id = job.run_remote()
```

### Row-based ingestion

Our basic ingestion is row-based, where the user set the maximum number of rows per each
chunk and file.

```python
job = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    explode_geometries=True,
    partitioning_method="rows",
    partitioning_maximum_per_file=100,
    partitioning_maximum_per_chunk=10,
)
job_id = job.run_remote()
```

### Area-based ingestion

Fused also supports area-based ingestion, where the number of rows in each partition is
determined by the sum of their area.

```python
job = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    output=f"fd://census/dc_tract_area",
    explode_geometries=True,
    partitioning_method="area",
    partitioning_maximum_per_file=None,
    partitioning_maximum_per_chunk=None,
)
job_id = job.run_remote()
```

### Geometry subdivision

It's also possible to subdivide geometries in the ingestion process.

```python
job = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    output=f"fd://census/dc_tract_geometry",
    explode_geometries=True,
    partitioning_method="area",
    partitioning_maximum_per_file=None,
    partitioning_maximum_per_chunk=None,
    subdivide_start=0.001,
    subdivide_stop=0.0001,
    subdivide_method="area",
)
job_id = job.run_remote()
```

Once ingestion completes,
[`fused.experimental.open_table`](/reference/fused/experimental/#open_table) returns the
corresponding `Table` object.

The notebook _repr_ provides insight into the Table structure.

- Each table has one or more _files_, which are spatially partitioned.
- Each file has one or more _chunks_, which are again spatially partitioned within the
  file.

Optionally, tables can be part of a `Dataset`, which consists of one or more _tables_.

```python
census_tracts = fused.experimental.open_table(f"fd://census/dc_tract")
census_tracts
```

### Ingest non-geospatial

Ingest a table that doesn't have a spatial component.

```python
job = fused.ingest_nongeospatial(
    input=df,
    output="s3://sample-bucket/file.parquet",
).run_remote()
```

