---
id: cache
title: Caching
tags: [cache]
sidebar_position: 5
---

# Caching

_This pages explains how caching makes Fused more responsive & some best practices for making the best use of it_

## Caching Basics

The goal of Fused is to make developing & running code faster for data scientists. This is done by using [efficient file formats](/core-concepts/data-ingestion/file-formats/) and making [UDFs simple to run](/core-concepts/run-udfs/). On top of those, Fused relies heavily on caching to make recurring calls much faster.

At a high level, caching is storing the output of a function run with some input so we can directly access the result next time that function is called with the same input, rather than re-computing it to save time & processing cost.

![Function + Input run](/img/core-concepts/caching/function_input_run_cache.png)

_The first run of a [Function + Input] is processed, but the next time that same combination is called, the result is retrieved much faster_

As soon as either the function or the inputs change however, the output needs to be processed (as the result of this new combination has not been computed before)

![Different Function + Input run](/img/core-concepts/caching/running_different_function.png)

Fused uses a few different types of cache, but they all work in this same manner


## Caching any Python function: [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache)

### Locally

Any Python function, either inside a UDF or even locally on your machine can be cached using the [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache) decorator around it:

```python {5} showLineNumbers
# This works locally on your machine
import python
from datetime import datetime

@fused.cache(cache_max_age='30s')
def telling_time():
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    return current_time

telling_time()
```

![Fused_cache_function_locally](/img/core-concepts/caching/fused_cache_function.png)

As seen in the debug logs, your cached data will be saved under `/tmp/cached_data/tmp/` locally.

:::tip
Similar to how this works with [`fused.run()`](/python-sdk/top-level-functions/#run), you can overwrite [`cache_max_age`](/core-concepts/cache/#defining-your-cache-lifetime-cache_max_age) when executing your function directly:

```python showLineNumbers
telling_time(cache_max_age="0s") # Overwrite cache duration to be 0s, i.e. no caching
```
:::

### Inside a UDF

This also works inside a UDF by passing [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache) decorator around any function:

```python {5} showLineNumbers
@fused.udf
def udf():
    import pandas as pd

    @fused.cache
    def load_data(i):
        # Do heavy processing here
        return pd.DataFrame({"id": [i]})

    df_first = load_data(i=1)
    df_first_repeat = load_data(i=1)
    df_second = load_data(i=2)

    return pd.concat([df_first, df_first_repeat, df_second])
```

Under the hood:
- The first time Fused sees the function code and parameters, Fused runs the function and stores the return value in a cache.
    - This is what happens in our example above, line 10: `load_data(i=1)`
- The next time the function is called with the same parameters and code, Fused skips running the function and returns the cached value
    - Example above: line 11, `df_first_repeat` is the same call as `df_first` so the function is simply retrieved from cache, not computed
- As soon as the function _or_ the input changes, Fused re-computes the function
    - Example above: line 12 as `i=2`, which is different from the previous calls

**Implementation Details**

A function cached with [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache) is:
- Cached for [12h by default](/python-sdk/top-level-functions/#fusedcache) (can be changed with [`cache_max_age`](/core-concepts/cache/#defining-your-cache-lifetime-cache_max_age))
- Stored as pickle file on `mount/`

### Benchmark: With / without [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache)

Using [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache) is mostly helpful to cache functions that have long, repetitive calls like for example loading data from slow file formats.

Here are 2 simple UDFs to demonstrate the impact:
- `without_cache_loading_udf` -> Doesn't use cache
- `with_cache_loading_udf` -> Caches the loading of a CSV

```python {6} showLineNumbers
@fused.udf
def without_cache_loading_udf(
    ship_length_meters: int = 100,
    ais_path: str = "s3://fused-users/fused/file_format_demo/AIS_2024_01_01_100k_points.csv"
):
    # @fused.cache
    def load_ais_data(ais_path: str):
        import pandas as pd
        return pd.read_csv(ais_path)

    ais = load_ais_data(ais_path)

    return ais[ais.Length > ship_length_meters]
```

and the same:
```python {6} showLineNumbers
@fused.udf
def with_cache_loading_udf(
    ship_length_meters: int = 100,
    ais_path: str = "s3://fused-users/fused/file_format_demo/AIS_2024_01_01_100k_points.csv"
):
    @fused.cache
    def load_ais_data(ais_path: str):
        import pandas as pd
        return pd.read_csv(ais_path)

    ais = load_ais_data(ais_path)

    return ais[ais.Length > ship_length_meters]
```

Comparing the 2:

![Caching benchmark](/img/core-concepts/caching/caching_benchmark.png)

### Best Practices: [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache)

Caching a local function or inside a UDF works best for:
- Loading data from slow formats (CSV, Shapefile)
- Repetitive operations that can take a long amount of processing

However, be wary of relying on [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache) to load very large (>10Gb) datasets as cache is only stored for a few hours by default and is over-written each time you change the cached function or inputs.

Look into [ingesting your data](/core-concepts/data-ingestion/) in partitioned [cloud native formats](/core-concepts/data-ingestion/file-formats/) if you're working with large datasets.

:::tip
The line between when to ingest your data or use `@fused.cache` to load data inside a UDF is a bit blurry. Check [this section](/core-concepts/data-ingestion/why-ingestion/#using-cache-as-a-single-use-ingester) for more
:::

### Example use cases

You can look at some real-world use cases in some of our Examples:
- [Caching a STAC catalog request](/user-guide/examples/dark-vessel-detection/#41-cleaning-our-sentinel-1-udf) when fetching Sentinel 1 radar satellite image in our Dark Vessel Detection example
- [Read about Jeff Faudi's use of `@fused.cache`](/blog/ai-for-object-detection-on-50cm-imagery/#implementing-aircraft-detection) in running an ML-inference model for aircraft detection. (See the [public UDF](https://github.com/fusedio/udfs/tree/main/public/DL4EO_Airplane_Detection) for yourself)

## Caching a UDF

While [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache) allows you to cache functions locally or _inside_ UDFs, UDFs ran with [`fused.run()`](/python-sdk/top-level-functions/#run) are cached by default on Fused server.

You can create a token for your UDF in Python by first saving your UDF to Fused server:

```python showLineNumbers
@fused.udf
def slow_caching_udf():
    import time
    import pandas as pd
    
    time.sleep(5)
    
    return pd.DataFrame({"output": ["I'm done running my long task!"]})

fused.run(slow_caching_udf)
```

We can demonstrate this caching with a UDF that has a `time.sleep(5)` in it. Running this same UDF twice:

![Cached_fused_run_udf](/img/core-concepts/caching/cached_fused_run_udf.png)

This means that UDFs that are repeatably called with `fused.run()` become much more responsive. Do remember once again that UDFs are recomputed each time either anything in the UDF function or the inputs change!

**Implementation Details**

Cached UDF are:
- Stored for 90d by default (see [Python SDK](/python-sdk/top-level-functions/#fusedudf) for more details)
- Stored on S3
- You can overwrite the cache age by passing [`cache_max_age`](/core-concepts/cache/#defining-your-cache-lifetime-cache_max_age) either when defining the UDF with [`@fused.udf(cache_max_age)`](/python-sdk/top-level-functions/#fusedudf) or when running the UDF with [`fused.run(udf, cache_max_age)`](/python-sdk/top-level-functions/#run)

:::note Default arguments are evaluated when defining the function
Note that UDFs work similarly to regular Python functions, default arguments are evaluated when defining the function, not when calling it.

For example:
```python
import datetime

@fused.udf
def abc(d: str = datetime.datetime.now().strftime('%Y-%m-%D')):
    print("with default", d)
```

and
```python
@fused.udf
def abc(d: str = None):
    import datetime
    d = datetime.datetime.now().strftime('%Y-%m-%D')
    print("with default", d)
```

Will both be cached similarly (i.e. calling either of these functions 2 times consecutively will return the cached results).
:::

## Advanced

### Caching & [`bounds`](/core-concepts/filetile/#the-bounds-object)

Pass [`bounds`](/core-concepts/filetile/#the-bounds-object) to make the output unique to each [Tile](/core-concepts/filetile/#tile).

```python showLineNumbers
@fused.udf
def udf(bounds: fused.types.Bounds=None):

    @fused.cache
    def fn(bounds):
        # convert bounds to tile
        common_utils = fused.load("https://github.com/fusedio/udfs/tree/bb712a5/public/common/").utils
        zoom = common_utils.estimate_zoom(bounds)
        tile = common_utils.get_tiles(bounds, zoom=zoom)
        return tile

    return fn(bounds)
```

Note that this means that if you're running your Tile UDF in Workbench, every time you pan around on the [map](/workbench/udf-builder/map/) you will cache a new file

For this reason, it's recommend to keep cache for tasks that _aren't_ dependent on your `bounds` when possible, for example:

```python {5} showLineNumbers
@fused.udf
def udf(bounds: fused.types.Bounds=None):

    @fused.cache
    def loading_slow_geodataframe(data_path):
        ...
        return gdf

    # convert bounds to tile
    common_utils = fused.load("https://github.com/fusedio/udfs/tree/bb712a5/public/common/").utils
    zoom = common_utils.estimate_zoom(bounds)
    tile = common_utils.get_tiles(bounds, zoom=zoom)

    # Loading of our slow data does not depend on bounds so can be cached even if we pan around
    gdf = loading_slow_geodataframe()
    gdf_in_bounds = gdf[gdf.geometry.within(tile.iloc[0].geometry)]

    return gdf_in_bounds
```

### Defining your cache lifetime: `cache_max_age`

You can define how long to keep your cache data for with `cache_max_age`. Valid time units include:
- Seconds (`s`)
- Minutes (`m`)
- Hours (`h`)
- Days (`d`)

Examples: `24h` (24 hours), `30m` (30 minutes), `10s` (10 seconds)


:::note
**Cache Behavior:** UDF executions are cached by default. To bypass caching and ensure fresh results, pass `cache_max_age="0s"` in your `fused.run()` call.
:::

```python showLineNumbers
@fused.udf
def udf():

    @fused.cache(
        cache_max_age="24h" # Your cache will stay available for 24h
    )
    def loading_slow_geodataframe(data_path):
        ...
        return gdf

    return gdf
```

This also works with [`@fused.udf()`](/python-sdk/top-level-functions/#fusedudf) & [`fused.run()`](/python-sdk/top-level-functions/#run):
```python showLineNumbers
@fused.udf(cache_max_age="24h") # This UDF will be cached for 24h after its initial run
def udf(path):

    gdf = gpd.read_file(path)

    return gdf
```

This UDF will be cached from the moment it's executed with `fused.run(udf)` for as long as is defined in `cache_max_age`:

```python showLineNumbers
fused.run(udf)
```

If you run `fused.run(udf)` again with no changes to `udf`, then for the next 24h `fused.run(udf)` will return a cached result. This is both faster & cheaper (saving on compute) while giving you control over how long to keep your cache for.

{/* NOTE: This only works with a token for now! */}
You can also overwrite the `cache_max_age` defined in `udf` when running your UDF:

```python showLineNumbers
fused.run(udf, cache_max_age="12h")
```

`udf` results will now only be cached for `12h`, even if `udf` was defined with a `cache_max_age` of `24h`:

The age of your cache is defined as follows:
- By default a UDF is cached for 90 days.
- If `@fused.udf(cache_max_age)` is defined, this new cache age overwrites the default.
- If `fused.run(udf, cache_max_age)` is passed, then this cache age takes priority over default & `@fused.udf(cache_max_age)`

### Resetting cache: `cache_reset`

Sometimes you might want to reset your cache, when for example:
- Running a UDF with unknown `cache_max_age`, and you want to make sure you're getting fresh results
- Having a `try / except` block to reset cache if your default UDF with cache fails.

You can easily do this by passing `cache_reset=True`:

```python showLineNumbers
fused.run(udf, cache_reset=True)
```

This also works in combination with [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache):

```python showLineNumbers
@fused.cache(cache_reset=True)
def my_function():
    ...
    return gdf
```

<details>
<summary>Example use case for `cache_reset`</summary>

Defining a UDF that simply returns the current time:
```python showLineNumbers
import fused

@fused.udf
def udf():
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
```

Running this a first time:
```python showLineNumbers
fused.run(udf)
```

Returns:
```bash
2025-06-06 10:00:00
```

Running this a second time:
```python showLineNumbers
fused.run(udf)
```

Returns a cached result:
```bash
Cached UDF result returned.
2025-06-06 10:00:00
```

This is because UDFs are [cached by default](/core-concepts/cache/#caching-a-udf) even without passing any [`cache_max_age`](/core-concepts/cache/#defining-your-cache-lifetime-cache_max_age) argument

We can break this cache by passing `cache_reset=True`:

```python showLineNumbers
fused.run(udf, cache_reset=True)
```

Returns:
```bash
2025-06-06 10:00:12
```

</details>

{/* TODO: This needs to be linked to the Python SDK page once its updated */}
{/* :::tip
    Read more about this in the [Python SDK page on `@fused.cache`](/python-sdk/top-level-functions/#fusedcache)
::: */}

{/* TODO: Don't want to expose this just yet  */}
{/* ### Caching on `local` or `mount` storage

Your cache is by default saved to `mount/`. This means if you or a team mate runs the same function with the same input they can also leverage your previously cached functions

You can however decide to only have this available to each individual instance by passing `storage="local"`. There are a few benefits / reasons to do this:
- Using `@fused.cache` on regular Python functions when developing locally:
    - You don't need to even use [`fused.run()`](/core-concepts/run-udfs/run-small-udfs/#fusedrun), you could use `@fused.cache` without ever using any other Fused functionality

```python {5} showLineNumbers
@fused.cache(
    storage="local"
)
def local_function_load(data_path):
    ...
    return gdf

gdf = local_function_load()
```

:::tip
    Read more about this in the [Python SDK page on `@fused.cache`](/python-sdk/top-level-functions/#fusedcache)
::: */}
