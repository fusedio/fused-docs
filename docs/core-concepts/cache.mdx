---
id: cache
title: Caching
tags: [cache]
sidebar_position: 5
---

{/* TODO: 
Intro concept of caching in Fused: Goal of Fused is to make developing & running faster. Caching can be a smart way to make recurring requests more responsive
Fused has 2 main cache types:
- `@fused.cache` decorator
    - Demonstrate (probably in notebook)
    - Show how to use
    - Explain *when* someone would want to use it (it's not always helpful)
        - Incredibly helpful for making workbench more responsive: query data 1 time and then make operations on it
        - Can be used as "1 time ingestion" for non partioned files
    - Mention limits
        - 24h limit
        - Changes on each code or input change, so quite brittle
- UDF caching 
    - Demonstrate (also in notebook probably: call same UDF 1 first time, then make same call again -> Should be faster)
    - Explain when this is helpful
        - Show in workbench toggle to turn this on: UDF Builder -> Settings -> Share (on by default)
        - In code somewhere?
- Caching best practices
    - When NOT to use cache
        - Ingesting data instead, prevents from having to cache things all time -> Useful when data is used many times in different places
        - When data is really too big to even be loaded in a single UDF
        Caching is really at it's best to speed up tasks that would take a few seconds or tens of seconds
*/}

{/* Caching stores the result of slow function calls so they only need to run once. This persists objects across reruns and makes UDFs faster. */}


# Caching

_This pages explains how caching makes Fused more responsive & some best practices for making the best use of it_

## Caching Basics

The goal of Fused is to make developing & running code faster for data scientists. This is done by using [efficient file formats](/core-concepts/data_ingestion/file-formats/) and making [UDFs simple to run](/core-concepts/run-udfs/). On top of those, Fused relies heavily on caching to make recurring calls much faster.

At a high level, caching is storing the output of a function run with some input so we can directly access the result next time that function is called with the same input, rather than re-computing it to save time & processing cost.

import FunctionRun from '@site/static/img/core-concepts/caching/function_input_run_cache.png';

<div style={{textAlign: 'center'}}>
<img src={FunctionRun} alt="Function + Input run" style={{width: 800,}} />
</div>

_The first run of a [Function + Input] is processed, but the next time that same combination is called, the result is retrieved much faster_

As soon as either the function or the inputs change however, the output needs to be processed (as the result of this new combination has not been computed before)

import DifferentFct from '@site/static/img/core-concepts/caching/running_different_function.png';

<div style={{textAlign: 'center'}}>
<img src={DifferentFct} alt="Different Function + Input run" style={{width: 800,}} />
</div>

Fused uses a few different types of cache, but they all work in this same manner


## Caching a function inside a UDF: [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache)

Any function inside a UDF can cached using [`@fused.cache`](/python-sdk/top-level-functions/#fusedcache).

```python showLineNumbers
@fused.udf
def udf():
    import pandas as pd

    @fused.cache
    def load_data(i):
        return pd.DataFrame({'id': [i]})

    df_first = load_data(i=1)
    df_second = load_data(i=2)
    return pd.concat([df_first, df_second])
```

The first time Fused sees the function code and parameters, Fused runs the function and stores the return value in a cache. The next time the function is called with the same parameters and code, Fused skips running the function and returns the cached value.


### Advanced


Pass [`bbox`](/core-concepts/filetile/#the-bbox-object) to make the output unique to each [Tile](/core-concepts/filetile/#tile).


```python showLineNumbers
@fused.udf
def udf(bbox: fused.types.TileGDF=None):

    @fused.cache
    def fn(bbox):
        return bbox

    return fn(bbox)
```


{/* NOTE: Commenting this out for now, as we haven't come across use cases where anyone would use this for now */}
{/* Set a custom cache directory with the optional `path` parameter.

```python showLineNumbers
@fused.udf
def udf():
    import pandas as pd

    @fused.cache(path='optional_cache_dir')
    def fn():
        return pd.DataFrame()

    return fn()
``` */}



{/* NOTE: Same, commenting this out for now as it doesn't add much so far */}
{/* Reset the cache by running the function once with `reset=True`.

```python showLineNumbers
@fused.udf
def udf():
    import pandas as pd

    @fused.cache(reset=True)
    def fn():
        return pd.DataFrame()

    return fn()
``` */}

### Best practices

{/* 
TODO:
Works best when caching repetitive queries where function AND input don't change so:
- Want to cache loading data function, especially for slow data (pd.read_csv() for example or `rio.open()`)
    -> Allows to load data 1 time, but do different operations on it as you explore your data
- Repetitive operations that can take long amount of processing
- But not the best to rely for large data, at this point ingest might make more sense
 */}

## Caching a UDF

{/* 
TODO:
- UDFs are directly cached by default, so calling `fused.run(my_udf)` again without any change will not change anything
    - especially true if this is a File UDF (and inputs don't change that much)
    - For tile -> does change frequently as every `bbox` is different
- In workbench can turn this off (show screenshot). On by default
 */}

