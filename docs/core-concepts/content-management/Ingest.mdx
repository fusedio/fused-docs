---
title: Ingest your own data
sidebar_label: Ingest
path: basics/tutorials/ingest/ingest
description: Tutorial on how to ingest parquet data with Fused.
sidebar_position: 4
keywords:
    - ingest
    - run_remote
---

import LinkButtons from "@site/src/components/LinkButtons.jsx";
import CellOutput from "@site/src/components/CellOutput.jsx";
import {BokehFigure, PlotlyFigure} from "@site/src/components/Plotting.jsx";
import Tag from '@site/src/components/Tag'

This guide explains how to use `fused.ingest` to geopartition and load vector tables into an S3 bucket so they can quickly be queried with Fused.

## Ingest data

To start an ingestion job, call [`run_remote`](/python-sdk/top-level-functions/#jobrun_remote) on the job object returned by [`fused.ingest`](/python-sdk/top-level-functions/#ingest).

```python showLineNumbers
job = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    output=f"fd://census/dc_tract",
)
job_id = job.run_remote()
```

The ingestion job first uploads the table specified by the `input` parameter using [fused.upload](/python-sdk/top-level-functions/#upload). It then geopartitions the table, creating chunks for spatial partitions. Finally, it writes a parquet table to the S3 path specified by the `output` parameter. Along with the table records, the resulting parquet file contains two metadata files: `main` and `fused`.

View the ingestion job status and logs in [fused.io/profile#jobs](https://www.fused.io/profile#jobs). Monitor and manage the job with the following methods:

```python showLineNumbers
# View the job status
job_id.status

# Follow the job logs
job_id.tail_logs()

# Get the job logs
job_id.print_logs()

# Cancel the job
job_id.cancel()
```

Ingested tables can easily be read with the Fused utility function `table_to_tile`, which spatially filters the dataset and reads only the chunks within a specified polygon.

```python showLineNumbers
@fused.udf
def udf(bbox, table="s3://fused-asset/infra/building_msft_us/"):
    utils = fused.load("https://github.com/fusedio/udfs/tree/eda5aec/public/common/").utils
    return utils.table_to_tile(bbox, table)
```

The following sections cover common ingestion implementations. It's recommended to run ingestion jobs from a Python Notebook or [this web app](https://www.fused.io/workbench#app/s/i/fa_3sY9SPDK9sqyHoR8NYm14H).

### Ingest a table from a URL

Ingests a table from a URL and writes it to an S3 bucket specified with [`fd://`](/core-concepts/content-management/file-system/#fd-s3-bucket).

```python showLineNumbers
import fused

job_id = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    output=f"fd://census/dc_tract",
).run_remote()
```

:::info

If you encounter the message
`HTTPError: {'detail': 'Quota limit: Number of running instances'}`, please contact Fused to increase the number of workers in your account.

:::


### Ingest multiple files

```python showLineNumbers
import fused

job_id = fused.ingest(
    input=["s3://my-bucket/file1.parquet", "s3://my-bucket/file2.parquet"],
    output=f"fd://census/dc_tract",
).run_remote()
```

:::warning

To ingest multiple local files, first upload them to S3 with [fused.upload](/python-sdk/top-level-functions/#upload) then specify an array of their S3 paths as the input to ingest.

:::

### Row-based ingestion

Standard ingestion is row-based, where the user sets the maximum number of rows per chunk and file.

Each resulting table has one or more _files_ and each file has one or more _chunks_, which are spatially partitioned. By default, ingestion does a best effort to create the number of files specified by `target_num_files` (default `20`), and the number of rows per file and chunk can be adjusted to meet this number.

```python showLineNumbers
job_id = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    explode_geometries=True,
    partitioning_method="rows",
    partitioning_maximum_per_file=100,
    partitioning_maximum_per_chunk=10,
).run_remote()
```

### Area-based ingestion

Fused also supports area-based ingestion, where the number of rows in each partition is
determined by the sum of their area.

```python showLineNumbers
job_id = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    output=f"fd://census/dc_tract_area",
    explode_geometries=True,
    partitioning_method="area",
    partitioning_maximum_per_file=None,
    partitioning_maximum_per_chunk=None,
).run_remote()
```

### Geometry subdivision

Subdivide geometries during ingestion. This keeps operations efficient when geometries have many vertices or span large areas.

```python showLineNumbers
job_id = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    output=f"fd://census/dc_tract_geometry",
    explode_geometries=True,
    partitioning_method="area",
    partitioning_maximum_per_file=None,
    partitioning_maximum_per_chunk=None,
    subdivide_start=0.001,
    subdivide_stop=0.0001,
    subdivide_method="area",
).run_remote()
```

### Ingest GeoDataFrame

Ingest a [GeoDataFrame](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.html) directly.

```python showLineNumbers
job_id = fused.ingest(
    input=gdf,
    output="s3://sample-bucket/file.parquet",
).run_remote()
```

### Ingest non-geospatial

Ingest a table that doesn't have a spatial component.

```python showLineNumbers
job_id = fused.ingest_nongeospatial(
    input=df,
    output="s3://sample-bucket/file.parquet",
).run_remote()
```

## Troubleshooting

As with other Fused batch jobs, ingestion jobs require server allocation for the account that initiates them. If you encounter the following error message, please contact the Fused team to request an increase.

```text
Error: `Quota limit: Number of running instances`
```
