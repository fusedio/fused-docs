---
title: Ingest your own data
sidebar_label: Ingest
path: basics/tutorials/ingest/ingest
description: Tutorial on how to ingest parquet data with Fused.
sidebar_position: 4
---

import LinkButtons from "@site/src/components/LinkButtons.jsx";
import CellOutput from "@site/src/components/CellOutput.jsx";
import {BokehFigure, PlotlyFigure} from "@site/src/components/Plotting.jsx";
import Tag from '@site/src/components/Tag'

This guide explains how to use `fused.ingest` to geopartition and load vector tables into an S3 bucket so they can quickly be queried with Fused.

## Ingest data


[`fused.ingest`](/python-sdk/top-level-functions/#ingest) first uploads the table specified by the `input` parameter using [fused.upload](/python-sdk/top-level-functions/#upload). It then geopartitions the table, creating chunks for spatial partitions. Finally, it writes a parquet table to the S3 path specified by the `output` parameter. Along with the table records, the resulting parquet file contains two metadata files: `main` and `fused`.

Ingested tables can easily be read with the Fused utility function [`table_to_tile`](https://github.com/fusedio/udfs/blob/9bfb5d0/public/common/utils.py#L90), which spatially filters the dataset and reads only chunks that fall within a specified polygon.

```python showLineNumbers
@fused.udf
def udf(bbox, table="s3://fused-asset/infra/building_msft_us/"):
    utils = fused.load("https://github.com/fusedio/udfs/tree/eda5aec/public/common/").utils
    return utils.table_to_tile(bbox, table)
```


The following sections cover common ingestion implementations. It's recommended they run from a Python Notebook.


### Ingest a table from a URL

Ingests a table from a URL and writes it to an S3 bucket specified with [`fd://`](/core-concepts/content-management/file-system/#fd-s3-bucket).


```python showLineNumbers
import fused

job = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    output=f"fd://census/dc_tract",
)
job_id = job.run_remote()
```

:::info

If you encounter the message
`HTTPError: {'detail': 'Quota limit: Number of running instances'}`, please contact Fused to increase the number of workers in to your account.

:::

While the job runs, follow its logs in a separate cell.

```python showLineNumbers
job_id.tail_logs()
```

Once ingestion completes, [`fused.experimental.open_table`](/reference/fused/experimental/#open_table) returns the corresponding `Table` object. Multiple tables may be organized within a `Dataset`.


```python showLineNumbers
census_tracts = fused.experimental.open_table(f"fd://census/dc_tract")
census_tracts
```

### Ingest multiple files


```python showLineNumbers
import fused

job = fused.ingest(
    input=["s3://my-bucket/file1.parquet", "s3://my-bucket/file2.parquet"],
    output=f"fd://census/dc_tract",
)
job_id = job.run_remote()
```

:::warning

To ingest multiple local files, first upload them with [fused.upload](/python-sdk/top-level-functions/#upload) then specify an array of their S3 paths as the input to ingest.

:::


### Row-based ingestion

Standard ingestion is row-based, where the user set the maximum number of rows per each
chunk and file.

Each resulting table has one or more _files_ and each file has one or more _chunks_, which are spatially partitioned. By default, ingestion does a best effort to create the number of files specified by `target_num_files` (default `20`), and the number of rows per file and chunk can be adjusted to meet this number.


```python showLineNumbers
job = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    explode_geometries=True,
    partitioning_method="rows",
    partitioning_maximum_per_file=100,
    partitioning_maximum_per_chunk=10,
)
job_id = job.run_remote()
```

### Area-based ingestion

Fused also supports area-based ingestion, where the number of rows in each partition is
determined by the sum of their area.

```python showLineNumbers
job = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    output=f"fd://census/dc_tract_area",
    explode_geometries=True,
    partitioning_method="area",
    partitioning_maximum_per_file=None,
    partitioning_maximum_per_chunk=None,
)
job_id = job.run_remote()
```

### Geometry subdivision

Subdivide geometries during ingestion. This keeps operations efficient when geometries have many vertices or span large areas.

```python showLineNumbers
job = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/TRACT/tl_rd22_11_tract.zip",
    output=f"fd://census/dc_tract_geometry",
    explode_geometries=True,
    partitioning_method="area",
    partitioning_maximum_per_file=None,
    partitioning_maximum_per_chunk=None,
    subdivide_start=0.001,
    subdivide_stop=0.0001,
    subdivide_method="area",
)
job_id = job.run_remote()
```

### Ingest GeoDataFrame

Ingest a [GeoDataFrame](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.html) directly.

```python showLineNumbers
job = fused.ingest(
    input=gdf,
    output="s3://sample-bucket/file.parquet",
).run_remote()
```



### Ingest non-geospatial

Ingest a table that doesn't have a spatial component.

```python showLineNumbers
job = fused.ingest_nongeospatial(
    input=df,
    output="s3://sample-bucket/file.parquet",
).run_remote()
```
