---
id: why-ingestion
title:  Why we need Ingestion
tags: [ingestion, cloud native]
sidebar_position: 1
---

# Data Ingestion

_This page will give you all the tools to make your data fast to read to make your UDFs more responsive._

{/*
Topics:
- Why do we need to do ingestion?
    - Cloud native
    - But also partitioned correctly
- How to do this ingestion?
    - Running `job = fused.ingest()` + `job.run_remote()`
- When is this needed
    - There's a section in the FAQ about when to ingest or not. This should be addressed in the ingestion page instead. 
- What happens after?
    - 
 */}

## What is this page about?

The whole purpose of Fused is to speed up data science pipelines. 
To make this happen we need the data we're working with to be responsive, regardless of the dataset. The ideal solution is to have all of our data sitting in RAM right next to our compute, but in real-world applications:
- Datasets (especially geospatial data) can be in the Tb or Pb range which rarely in storage, let alone RAM
- Compute needs to be scaled up and down depending on workloads.

One solution to this is to build data around **Cloud Optimized formats**: Data lives in the cloud but also leverages file formats that are fast to access. Just putting a `.zip` file than needs to be uncompressed every time on an S3 bucket still makes reading it very slow. Our ingested data should be:
- **On the cloud** so dataset size doesn't matter (AWS S3, Google Cloud Storage, etc.)
- **Partitioned** (broken down into smaller pieces that are fast to retrieve so we can load only sections of the dataset we need)

This makes it fast to read for any UDF (and any other cloud operation), so developing UDFs in [Workbench UDF Builder](/workbench/udf-builder/) & [running UDFs](/core-concepts/run-udfs/) is a lot faster & responsive!

## When is ingestion needed?

You don't _always_ need to ingest your file into a cloud, geo-partitioned format. There are a few situation when it might be simpler & faster to just load your data. 
Small files (< 100Mb ) that are fast to open (already in `.parquet` for example) that you only read once (note that it might be read 1x in your UDF but your UDF might be run many times)

Example of data you should ingest: 1Gb `.zip` of shapefile
- `.zip` means you need to unzip your file each time you open it and then read it. This slows down working with the data
- shapefile contains multiple files, it isn't the fastest to read

Example of data you don't need to ingest: 50Mb `.parquet`
- Even if the data isn't geo-partitioned, loading this data should be fast enough to make any UDF fast 

