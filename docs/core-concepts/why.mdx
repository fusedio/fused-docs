---
id: why
title:  Why UDFs
tags: [write, why]
sidebar_position: 0
---

Fused is a data analytics platform to write and deploy Python User Defined Functions (UDFs) behind HTTP endpoints and interactive applications.

- Read files in cloud storage with UDFs
- Write and share UDFs with ease
- Run UDFs from anywhere with simple HTTP calls
- Scale and parallelize without managing infrastructure
- Create apps that run UDFs

## What is a UDF?

UDFs are Python functions that can be called from anywhere to apply a specific operation to data. Fused creates an endpoint for every UDFs that can be called to run the function and return its output. This allows Fused to easily integrate with data applications and deliver dynamically generated data on-demand.

{/* ![alt text](https://fused-magic.s3.us-west-2.amazonaws.com/docs_assets/ecosystem_diagram.png) */}


import { DotLottieReact } from "@lottiefiles/dotlottie-react";

<DotLottieReact src="https://lottie.host/7aebb036-6aba-49f7-8e8e-2b57f8d11bfa/31927KRYv4.json" loop autoplay/>

_This diagram shows how UDFs link upstream datasets with downstream data platforms using standard Python libraries._


This of UDFs as versatile building blocks to load and transform data across a range of use cases, including geospatial. They can be used, for example, as virtual datasets, file readers, and workflow tasks.

## Virtual Datasets

UDFs can be used as virtual datasets, similar to database views, to deliver data behind an HTTP endpoint. They can return data in formats defined at call time based on the needs of the client application, such as tiffs, Parquet, GeoJSON, and others. This eliminates the need to pre-process or transfer datasets ahead of time.

{/* todo: materialize, caching */}

## File Readers

UDFs can also be used to open files of different formats, like Parquet, CSV, and GeoJSON. This provides a standard interface to easily explore files in buckets and eliminates the need to move, copy, or transform entire datasets.

## Workflow Tasks

UDFs can serve as reusable tasks in analysis pipelines that easily integrate with 3rd party applications to load, process, and write data. Multiple UDFs can be assembled like DAGs to create complex workflows that run and return data on demand via HTTP requests.
