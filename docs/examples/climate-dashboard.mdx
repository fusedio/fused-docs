---
id: climate-dashboard
title: Climate Dashboard
sidebar_label: Climate Dashboard
sidebar_position: 7
---

import LazyReactPlayer from '@site/src/components/LazyReactPlayer'

# Building a Climate dashboard

We're going to build an interactive dashboard of global temperature data, after processing 1TB of data in a few minutes!

### Install `fused`

```python
pip install "fused[all]"
```

Read more about installing Fused [here](/guide/advanced-setup/local-installation).

<details>
<summary>Authenticate in Fused</summary>

In a notebook:

```python
from fused.api import NotebookCredentials

credentials = NotebookCredentials()
print(credentials.url)
```

Follow the link to authenticate.

Read more about [authenticating in Fused](/guide/advanced-setup/local-installation).

</details>

{/* TODO:  Remove this to clean up. Not needed anymore*/}
{/* ### Your first User Defined Function

Fused is built around the concept of [User Defined Functions (UDFs)](/guide/getting-started/first-udf-basics). These are serverless Python functions:

```python
@fused.udf
def udf(path: str = 's3://fused-asset/data/era5/t2m/datestr=2024-01-01/0.parquet'):
    import pandas as pd
    df = pd.read_parquet(path, columns=['daily_mean'])

    return df.head()
```

Call your UDF to execute it on Fused server:

```python
fused.run(udf)
```

You get your results back in a couple of seconds:

```shell
>>> 	daily_mean
hex	
644014746717455876	268.686016
644014747002884118	268.747975
644014747398193161	268.623347
``` */}

### Processing 1 month

{/* TODO: Have link to ingestion pipeline later on */}
[ERA5](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5) global weather data was ingested using Fused ingestion pipeline.

```python
import fused
```

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs className="unique-tabs">
  <TabItem value="DuckDB">
    ```python
      @fused.udf
      def udf(
          month: str = "2024-01",
      ):
          import duckdb
          result = duckdb.sql(f"""
            SELECT 
                datestr::VARCHAR as datestr,
                ROUND(AVG(daily_mean), 2) as daily_mean_temp
            FROM 's3://fused-asset/data/era5/t2m/datestr={month}-*/*.parquet'
            GROUP BY datestr
            ORDER BY datestr
          """).df()

          # Mount is accessible by Fused UDFs / Workbench
          output_fp = fused.file_path(f"monthly_climate/{month}.pq")
          result.to_parquet(output_fp)

          return output_fp
    ```
  </TabItem>
  <TabItem value="Pandas">

    NOTE: `pandas` approach is a bit slower than DuckDB.

    ```python
    @fused.udf
    def udf(month: str = "2024-01",):
        import pandas as pd

        files = fused.api.list(f"s3://fused-asset/data/era5/t2m/datestr={month}-")

        dfs = [pd.read_parquet(file, columns=['daily_mean']).assign(datestr=file.split('datestr=')[1].split('/')[0]) for file in files]
        result = pd.concat(dfs).groupby('datestr')['daily_mean'].mean().round(2).reset_index()

        # Mount is accessible by Fused UDFs / Workbench
        output_fp = fused.file_path(f"monthly_climate/{month}.pq")
        result.to_parquet(output_fp)
        
        return result
    ```

  </TabItem>
</Tabs>

Read more about [`fused.file_path()`](/python-sdk/api-reference/fused-file-path) and [mount](/guide/advanced-setup/file-system/#mntcache-disk)

Executing this from a notebook:
```python
fused.run(udf)
```

We only return the file path to limit moving data from Fused server < - > our notebook. Hence why we print the dataframe:

```shell
>>>   result.T=                         0           1   ...          29          30
datestr          2024-01-01  2024-01-02  ...  2024-01-30  2024-01-31
daily_mean_temp      277.85      277.63  ...      277.93      278.11
```

### 20 years of data (1TB in < 1min!)

Explore the available data for yourself in [File Explorer](https://www.fused.io/workbench/files?path=s3%3A%2F%2Ffused-asset%2Fdata%2Fera5%2Ft2m%2F)

We'll process 20 years of data:

```python
data_until = 2005

available_days = fused.api.list('s3://fused-asset/data/era5/t2m/')
recent_months = list(set([
   path.split('datestr=')[1][:7] for path in available_days 
   if int(path.split('datestr=')[1][:4]) >= data_until
]))
```

This corresponds to ~1TB of data!

<details>
<summary>Size of data quick calculation</summary>

Each file being about 140MB a quick back of the envelope calculation gives us:
```python
recent_days = [day for day in available_days if day.split('datestr=')[1][:7] in recent_months]
len(recent_days) * 140 / 1000 # size in GB of files we'll process
```

```bash
1005.62
```
</details>

Fused allows us to run a [UDF in parallel](/guide/working-with-udfs/udf-best-practices/scaling-out#parallel-execution). So we'll process 1 month of data across hundreds of jobs:

```python
results = fused.submit(
  udf, 
  recent_months, 
  max_workers=250, 
  collect=False
)
```

See a progress bar of jobs running:

```python
results.wait()
```

See how long all the jobs took:

```python
results.total_time()
```

```bash
>>> datetime.timedelta(seconds=40, ...)
```

**We just processed 20 years of worldwide global data, over 1TB in 40s!!**

We can now write a UDF that gets all the monthly data and aggregates it by month:

```python
@fused.udf(cache_max_age='0s')
def udf():
    import duckdb
    
    # Listing all files on our mount directory
    monthlys = fused.api.list(fused.file_path(f"monthly_climate/"))
    file_list = "', '".join(monthlys)
    
    result = duckdb.sql(f"""
       SELECT 
           LEFT(datestr, 7) as month,
           ROUND(AVG(daily_mean_temp), 2) as monthly_mean_temp
       FROM read_parquet(['{file_list}'])
       GROUP BY month
       ORDER BY month
    """).df()

    return result
```

Instead of running this locally, we'll open it in [Workbench](/workbench/overview), Fused's web-based IDE:

```python
# Save to Fused
udf.to_fused("monthly_mean_temp")

# Load again to get the Workbench URL
loaded_udf = fused.load("monthly_mean_temp")
```

Return `loaded_udf` in a notebook and you'll get a URL that takes you to Workbench:

```python
loaded_udf
```

Click on the link to open the UDF in Workbench. Click "+ Add to UDF Builder" 

![Monthly temperature aggregation in Workbench](/img/uses-cases/climate_dashboard/climate_agg.png)


{/* TODO: Add a screenshot of Table view in Wb */}

### Interactive graph (with AI)

You can use the AI Assistant to help you vibe code an interactive timeseries of your data

Simply ask the AI:

```
Make an interactive graph of the monthly temperature data
```

You can then share your graph:
- Save (`Cmd + S` on MacOS or click the "Save" button)
- Click "URL" button to see deployed graph!

Any time you make an update, your graph will automatically update!

<LazyReactPlayer 
  playsinline={true} 
  className="video__player" 
  playing={true} 
  muted={true} 
  controls 
  height="100%" 
  url="https://fused-magic.s3.us-west-2.amazonaws.com/workbench-walkthrough-videos/docs_rewrite/examples/climate_dashboard/sharing_grpah.mp4" 
  width="100%" 
/>
