---
id: data-formats-snippets
title: Data Formats
sidebar_label: Data Formats
sidebar_position: 4
draft: true
---

# Data Formats Quick Reference

Quick code snippets for reading and writing common data formats in Fused.

---

## Tables

### CSV

```python
import pandas as pd

# Read
df = pd.read_csv("s3://bucket/data.csv")

# Write
df.to_csv("fd://my-data/output.csv", index=False)
```

### Parquet

```python
import pandas as pd

# Read
df = pd.read_parquet("s3://bucket/data.parquet")

# Write
df.to_parquet("fd://my-data/output.parquet")
```

### Excel

```python
import pandas as pd

# Read
df = pd.read_excel("s3://bucket/data.xlsx")
```

### JSON

```python
import pandas as pd

# Read
df = pd.read_json("s3://bucket/data.json")

# Write
df.to_json("fd://my-data/output.json")
```

---

## Geospatial Tables

### GeoParquet

```python
import geopandas as gpd

# Read
gdf = gpd.read_parquet("s3://bucket/data.parquet")

# Write
gdf.to_parquet("fd://my-data/output.parquet")
```

### GeoJSON

```python
import geopandas as gpd

# Read
gdf = gpd.read_file("https://example.com/data.geojson")

# Write
gdf.to_file("fd://my-data/output.geojson", driver="GeoJSON")
```

### Shapefile (zipped)

```python
import geopandas as gpd

# Read from URL
gdf = gpd.read_file("https://example.com/data.zip")

# Read from S3
gdf = gpd.read_file("s3://bucket/data.zip")
```

---

## Raster Images

### GeoTIFF / Cloud Optimized GeoTIFF (COG)

```python
# Using Fused common utils
common = fused.load("https://github.com/fusedio/udfs/tree/main/public/common/")
arr = common.read_tiff(tile, "s3://bucket/image.tif")
```

```python
# Using rasterio directly
import rasterio
with rasterio.open("s3://bucket/image.tif") as src:
    arr = src.read()
```

### PNG/JPEG

```python
from PIL import Image
import requests
from io import BytesIO

response = requests.get("https://example.com/image.png")
img = Image.open(BytesIO(response.content))
```

---

## Cloud Storage Paths

| Provider | Format | Example |
|----------|--------|---------|
| Fused managed | `fd://` | `fd://my-data/file.parquet` |
| AWS S3 | `s3://` | `s3://bucket-name/path/file.parquet` |
| Google Cloud | `gs://` or `gcs://` | `gs://bucket-name/path/file.parquet` |
| Azure | `az://` | `az://container/path/file.parquet` |
| HTTP(S) | `https://` | `https://example.com/file.csv` |

---

## STAC Catalogs

```python
import pystac_client
import odc.stac

# Connect to STAC catalog
catalog = pystac_client.Client.open("https://earth-search.aws.element84.com/v1")

# Search for items
items = catalog.search(
    collections=["sentinel-2-l2a"],
    bbox=[-122.5, 37.5, -122.0, 38.0],
    datetime="2023-01-01/2023-12-31"
).item_collection()

# Load with odc.stac
ds = odc.stac.load(items, bands=["red", "green", "blue"])
```

---

## DuckDB Queries

```python
common = fused.load("https://github.com/fusedio/udfs/tree/main/public/common/")
con = common.duckdb_connect()

# Query S3 directly
df = con.sql("""
    SELECT * FROM read_parquet('s3://bucket/data.parquet')
    WHERE value > 100
    LIMIT 1000
""").df()
```

---

## Recommended Formats

| Data Type | Recommended Format | Why |
|-----------|-------------------|-----|
| Tables | **Parquet** | Columnar, compressed, fast |
| Geospatial tables | **GeoParquet** | Spatial indexing, cloud-native |
| Raster images | **Cloud Optimized GeoTIFF** | Tiled, overviews, partial reads |
| Large datasets | **Partitioned GeoParquet** | Use `fused.ingest()` |

For large datasets (&gt;1GB), use [`fused.ingest()`](/guide/data-input-outputs/read-write/geospatial/ingestion/) to create optimized, partitioned files.
