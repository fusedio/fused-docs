---
id: databases
title: Databases
sidebar_label: Databases
sidebar_position: 3
---

# Google Earth Engine & BigQuery

## Google Earth Engine

import CellOutput from "@site/src/components/CellOutput.jsx";
import Tag from '@site/src/components/Tag'

Fused interfaces [Google Earth Engine](https://earthengine.google.com/) with the Python [`earthengine-api`](https://github.com/google/earthengine-api) library. This example shows how to load data from GEE [datasets](https://developers.google.com/earth-engine/datasets) into Fused UDFs and read it with xarray.

### 1. Authenticate with a Google Service Account

Create a UDF to set your Google [Service Account credentials](https://developers.google.com/earth-engine/guides/service_account) in your Fused runtime [disk](/core-concepts/content-management/file-system/#mntcache-disk) in a file in the `/mnt/cache` directory.

```python showLineNumbers
@fused.udf
def udf():

    import os, json

    # Google Key as JSON
    data = {
        'type': 'service_account',
        'project_id': 'MYPROJECT',
        'private_key_id': '1234',
        'private_key': '-----BEGIN PRIVATE KEY-----...\n-----END PRIVATE KEY-----\n',
        'client_email': 'fused-account@MYPROJECT.iam.gserviceaccount.com',
        'client_id': '1234567',
        'auth_uri': 'https://accounts.google.com/o/oauth2/auth',
        'token_uri': 'https://oauth2.googleapis.com/token',
        'auth_provider_x509_cert_url': 'https://www.googleapis.com/oauth2/v1/certs',
        'client_x509_cert_url': 'https://www.googleapis.com/robot/v1/metadata/x509/fused-pg%40MYPROJECT.iam.gserviceaccount.com',
        'universe_domain': 'googleapis.com'
    }

    # Define the target path for the new GEE credentials file
    key_path = '/mnt/cache/gee_creds.json'

    # Write the loaded JSON data to the new file
    with open(key_path, 'w') as file:
        json.dump(data, file)
```

### 2. Load data from Google Earth Engine

Create a UDF to load data from a GEE ImageCollection and open it with xarray. Authenticate by passing the key file path to `ee.ServiceAccountCredentials`.

```python showLineNumbers
@fused.udf
def udf(bounds: fused.types.TileGDF=None, n=10):
    import ee
    import xarray

    common = fused.load("https://github.com/fusedio/udfs/tree/fbf5682/public/common/")

    # Authenticate GEE
    key_path = '/mnt/cache/gee_creds.json'
    credentials = ee.ServiceAccountCredentials("fused-account@fused-gee.iam.gserviceaccount.com", key_path)
    ee.Initialize(opt_url="https://earthengine-highvolume.googleapis.com", credentials=credentials)

    # Generate GEE bounding box for spatial filter
    geom = ee.Geometry.Rectangle(*bounds.total_bounds)
    scale = 1 / 2 ** max(0, bounds.z[0])  # A larger scale will increase your resolution per z but slow down the loading

    # Load data from a GEE ImageCollection
    ic = ee.ImageCollection("MODIS/061/MOD13A2").filter(
        ee.Filter.date("2023-01-01", "2023-06-01")
    )

    # Open with xarray (the `xee` package must be present for engine="ee" to work)
    ds = xarray.open_dataset(ic, engine="ee", geometry=geom, scale=scale).isel(time=0)

    # Transform image color with a utility function
    arr = common.arr_to_plasma(ds["NDVI"].values.squeeze().T, min_max=(0, 8000))
    return arr

```


## BigQuery - Option 1: Credentials file

Fused integrates with [Google BigQuery](https://cloud.google.com/bigquery/docs/introduction) with the Python [`bigquery`](https://cloud.google.com/python/docs/reference/bigquery/latest) library.

### 1. Authenticate with a Google Service Account

Create a UDF to set your Google [Service Account credentials](https://cloud.google.com/bigquery/docs/use-service-accounts) in your Fused runtime [disk](/core-concepts/content-management/file-system/#mntcache-disk) in a file in the `/mnt/cache` directory.

```python showLineNumbers
@fused.udf
def udf():

    import os, json

    # Google Key as JSON
    data = {
        'type': 'service_account',
        'project_id': 'MYPROJECT',
        'private_key_id': '1234',
        'private_key': '-----BEGIN PRIVATE KEY-----...\n-----END PRIVATE KEY-----\n',
        'client_email': 'fused-account@MYPROJECT.iam.gserviceaccount.com',
        'client_id': '1234567',
        'auth_uri': 'https://accounts.google.com/o/oauth2/auth',
        'token_uri': 'https://oauth2.googleapis.com/token',
        'auth_provider_x509_cert_url': 'https://www.googleapis.com/oauth2/v1/certs',
        'client_x509_cert_url': 'https://www.googleapis.com/robot/v1/metadata/x509/fused-pg%40MYPROJECT.iam.gserviceaccount.com',
        'universe_domain': 'googleapis.com'
    }

    # Define the target path for the new GEE credentials file
    key_path = '/mnt/cache/bq_creds.json'

    # Write the loaded JSON data to the new file
    with open(key_path, 'w') as file:
        json.dump(data, file)
```

### 2. Load data from BigQuery

Create a UDF to perform a query on a BigQuery dataset and return the results as a DataFrame or GeoDataFrame. Authenticate by passing the key file path to `service_account.Credentials`.

```python showLineNumbers
@fused.udf
def udf(bounds: fused.types.TileGDF=None, geography_column=None):
    from google.cloud import bigquery
    from google.oauth2 import service_account

    # This UDF will only work on runtime with mounted EFS
    key_path = "/mnt/cache/bq_creds.json"

    # Authenticate BigQuery
    credentials = service_account.Credentials.from_service_account_file(
        key_path, scopes=["https://www.googleapis.com/auth/cloud-platform"]
    )

    # Create a BigQuery client
    client = bigquery.Client(credentials=credentials, project=credentials.project_id)

    # Structure spatial query
    query = f"""
        SELECT * FROM `bigquery-public-data.new_york.tlc_yellow_trips_2015`
        LIMIT 10
    """

    if geography_column:
        return client.query(query).to_geodataframe(geography_column=geography_column)
    else:
        return client.query(query).to_dataframe()
```


## Big Query - Option 2: Secrets

If you already have a `gcs_secret` in Fused secrets, you can use it to access your GCP secrets. Otherwise you can simply create new secrets in the Fused secrets manager with:
- `GS_ACCESS_KEY_ID`
- `GS_SECRET_ACCESS_KEY`

You can for example use this to access the [Github Activity Data](https://console.cloud.google.com/marketplace/product/github/github-repos?inv=1&invt=Ab5M6w)

```python showLineNumbers
@fused.udf
def udf(repo_name: str = "athasdev/athas"):
    import os
    # This is not required if your account already has the `gcs_secret` in Fused secrets
    os.environ['GS_ACCESS_KEY_ID'] = fused.secrets["GS_ACCESS_KEY_ID"]
    os.environ['GS_SECRET_ACCESS_KEY'] = fused.secrets["GS_SECRET_ACCESS_KEY"]
    
    from google.cloud import bigquery
    # Initialize BigQuery client
    client = bigquery.Client()
    
    # Get total stars 
    total_query = f"""
        SELECT 
            repo.name as repository,
            COUNT(*) as total_stars
        FROM `githubarchive.day.202508*`
        WHERE type = 'WatchEvent' 
 --           AND repo.name = '{repo_name}'
        GROUP BY repository
    """
    
    total_query = f""" SELECT  * FROM `githubarchive.day.202508*` limit 10"""
    
    # Run the query
    query_job = client.query(total_query)
    
    # Convert to pandas DataFrame
    total_df = query_job.to_dataframe()
     
    return total_df
```