---
id: databases
title: Databases
sidebar_label: Databases
sidebar_position: 3
---

# Databases

Connect Fused to external databases like Snowflake and BigQuery.

## Snowflake

Set `user` and `password` in the Fused [secrets management UI](/workbench/preferences#secrets-management) first.

```python showLineNumbers
@fused.udf
def udf(query: str = 'SELECT CURRENT_VERSION()'):
    import snowflake.connector
    import pandas as pd
    
    try:
        conn = snowflake.connector.connect(
            user=fused.secret('SNOWFLAKE_USER'),
            password=fused.secret('SNOWFLAKE_PASSWORD'), 
            account='your_account_identifier',
            warehouse='your_warehouse',
            database='your_database',
            schema='your_schema'
        )
        
        # Execute query and return as DataFrame
        cursor = conn.cursor()
        cursor.execute(query)
        
        # Use pandas to read directly from cursor
        df = cursor.fetch_pandas_all()
        
        cursor.close()
        conn.close()
        
        return df
        
    except Exception as e:
        print(f"Snowflake connection failed: {e}")
        raise
```

Read more about [Snowflake's authentication](https://docs.snowflake.com/en/developer-guide/python-connector/python-connector-connect).

---

## BigQuery - Option 1: Credentials file

Fused integrates with [Google BigQuery](https://cloud.google.com/bigquery/docs/introduction) with the Python [`bigquery`](https://cloud.google.com/python/docs/reference/bigquery/latest) library.

### 1. Authenticate with a Google Service Account

Create a UDF to set your Google [Service Account credentials](https://cloud.google.com/bigquery/docs/use-service-accounts) in your Fused runtime [disk](/guide/advanced-setup/file-system/#mntcache-disk) in a file in the `/mnt/cache` directory.

```python showLineNumbers
@fused.udf
def udf():

    import os, json

    # Google Key as JSON
    data = {
        'type': 'service_account',
        'project_id': 'MYPROJECT',
        'private_key_id': '1234',
        'private_key': '-----BEGIN PRIVATE KEY-----...\n-----END PRIVATE KEY-----\n',
        'client_email': 'fused-account@MYPROJECT.iam.gserviceaccount.com',
        'client_id': '1234567',
        'auth_uri': 'https://accounts.google.com/o/oauth2/auth',
        'token_uri': 'https://oauth2.googleapis.com/token',
        'auth_provider_x509_cert_url': 'https://www.googleapis.com/oauth2/v1/certs',
        'client_x509_cert_url': 'https://www.googleapis.com/robot/v1/metadata/x509/fused-pg%40MYPROJECT.iam.gserviceaccount.com',
        'universe_domain': 'googleapis.com'
    }

    # Define the target path for the new GEE credentials file
    key_path = '/mnt/cache/bq_creds.json'

    # Write the loaded JSON data to the new file
    with open(key_path, 'w') as file:
        json.dump(data, file)
```

### 2. Load data from BigQuery

Create a UDF to perform a query on a BigQuery dataset and return the results as a DataFrame or GeoDataFrame. Authenticate by passing the key file path to `service_account.Credentials`.

```python showLineNumbers
@fused.udf
def udf(bounds: fused.types.TileGDF=None, geography_column=None):
    from google.cloud import bigquery
    from google.oauth2 import service_account

    # This UDF will only work on runtime with mounted EFS
    key_path = "/mnt/cache/bq_creds.json"

    # Authenticate BigQuery
    credentials = service_account.Credentials.from_service_account_file(
        key_path, scopes=["https://www.googleapis.com/auth/cloud-platform"]
    )

    # Create a BigQuery client
    client = bigquery.Client(credentials=credentials, project=credentials.project_id)

    # Structure spatial query
    query = f"""
        SELECT * FROM `bigquery-public-data.new_york.tlc_yellow_trips_2015`
        LIMIT 10
    """

    if geography_column:
        return client.query(query).to_geodataframe(geography_column=geography_column)
    else:
        return client.query(query).to_dataframe()
```


## Big Query - Option 2: Secrets

If you already have a `gcs_secret` in Fused secrets, you can use it to access your GCP secrets. Otherwise you can simply create new secrets in the Fused secrets manager with:
- `GS_ACCESS_KEY_ID`
- `GS_SECRET_ACCESS_KEY`

You can for example use this to access the [Github Activity Data](https://console.cloud.google.com/marketplace/product/github/github-repos?inv=1&invt=Ab5M6w)

```python showLineNumbers
@fused.udf
def udf(repo_name: str = "athasdev/athas"):
    import os
    # This is not required if your account already has the `gcs_secret` in Fused secrets
    os.environ['GS_ACCESS_KEY_ID'] = fused.secrets["GS_ACCESS_KEY_ID"]
    os.environ['GS_SECRET_ACCESS_KEY'] = fused.secrets["GS_SECRET_ACCESS_KEY"]
    
    from google.cloud import bigquery
    # Initialize BigQuery client
    client = bigquery.Client()
    
    # Get total stars 
    total_query = f"""
        SELECT 
            repo.name as repository,
            COUNT(*) as total_stars
        FROM `githubarchive.day.202508*`
        WHERE type = 'WatchEvent' 
 --           AND repo.name = '{repo_name}'
        GROUP BY repository
    """
    
    total_query = f""" SELECT  * FROM `githubarchive.day.202508*` limit 10"""
    
    # Run the query
    query_job = client.query(total_query)
    
    # Convert to pandas DataFrame
    total_df = query_job.to_dataframe()
     
    return total_df
```