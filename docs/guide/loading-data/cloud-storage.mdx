---
title: Cloud Storage
sidebar_label: Cloud Storage
sidebar_position: 3
description: Read and write to S3, GCS, and Azure Blob Storage
---

# Cloud Storage

Fused UDFs can read and write directly to any cloud storage provider. It's just Python.

```python
import pandas as pd
df = pd.read_parquet("s3://bucket/file.parquet")
```

---

## Supported Providers

| Provider | URL Prefix | Example |
|----------|------------|---------|
| Amazon S3 | `s3://` | `s3://my-bucket/data.parquet` |
| Google Cloud Storage | `gs://` | `gs://my-bucket/data.parquet` |
| Azure Blob Storage | `az://` | `az://container/data.parquet` |
| HTTP/HTTPS | `https://` | `https://example.com/data.csv` |
| Fused Storage | `fd://` | `fd://my-data/file.parquet` |

---

## Private Bucket Access

For private buckets, set up credentials in **Workbench → Preferences → Secrets**.

Then access normally - Fused handles authentication:

```python
df = pd.read_parquet("s3://my-private-bucket/data.parquet")
```

---

## Using Your Own S3 Bucket

You can configure Fused to write to your own S3 bucket by setting up an IAM policy.

**Steps:**
1. Create an IAM policy granting Fused access
2. Add your bucket credentials in Workbench Preferences
3. Use your bucket path in UDFs

For detailed setup instructions, see [Ingest to Your Own S3 Bucket](/guide/loading-data/geospatial-data-ingestion/ingest-your-data#ingest-to-your-own-s3-bucket).

---

## Code Examples

For detailed code snippets for each provider, see the **[Data Loading Reference](/reference/data-loading/)**.
