---
id: parallel
title: Parallel Execution
sidebar_label: Parallel
sidebar_position: 2
---

# Running Jobs in Parallel: `fused.submit()`

Sometimes you want to run a UDF over a list of inputs (for example running a [UDF that unzips a file over a list of files](/examples/dark-vessel-detection#33---run-this-udf-over-a-month-of-ais-data)). If each run itself is quite small, then you can run a batch of UDFs over a list of inputs.

Let's use a simple UDF to demonstrate:

```python showLineNumbers
@fused.udf
def udf(val):
    import pandas as pd
    return pd.DataFrame({'val':[val]})
```

Say we wanted to run this `udf` 10 times over:

```python showLineNumbers
inputs = [0,1,2,3,4,5,6,7,8,9]
```

## `fused.submit()`

Fused is built to help you scale your processing to huge datasets and the core of this ability is [`fused.submit()`](/python-sdk/top-level-functions/#fusedsubmit). You can run 1 UDF over a large number of arguments:

```python showLineNumbers
results = fused.submit(udf, inputs)
```

```bash
>>> 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 
```

Note that you will only see the progress bar if you are running the code in a notebook, Workbench does not yet currently stream the progress to the console.

[`fused.submit()`](/python-sdk/top-level-functions/#fusedsubmit) runs all these jobs in parallel and defaults to directly returning the results back to you as a dataframe:

```python showLineNumbers
print(results)
```

```
>>>
 		val
val
0	0	0
1	0	1
...
```

## Tips for using `fused.submit()`

- Check that your parameters are correctly setup with `debug_mode=True`:

```python showLineNumbers
single_run = fused.submit(udf, inputs, debug_mode=True)
```

- Start with a small number of jobs, then scale up:

```python showLineNumbers   
# Only running the first 5 inputs to make sure the UDF is working as expected
results = fused.submit(udf, inputs[:5])
```

- Check the runtime of each job:

```python showLineNumbers
# Run only 10 jobs and see how long each one took
results = fused.submit(udf, inputs[:5], collect=False)
print(results.times())
```

:::tip Job length rule of thumb: 30-45s
Aim for a single UDF that takes 30-45s. This gives you a "safety" margin as UDFs will timeout after 120s. So they can still take a bit longer and not time out.
:::

## Advanced Options

### Blocking vs non-blocking calls

By default we've set up [`fused.submit()`](/python-sdk/top-level-functions/#fusedsubmit) to be blocking, meaning it will wait for all the jobs to finish before returning the results.

However, you can set `collect=False` and then track the progress of jobs as they run:

```python showLineNumbers
results = fused.submit(udf, inputs, collect=False)
```

### Real time logs

- Show a progress bar of number of jobs completed:

```python showLineNumbers
print(results.wait())
```

```
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00, 9.31it/s]
```

- Show total time it took to run all the jobs:

```python showLineNumbers
print(results.total_time())
```

```
>>> datetime.timedelta(seconds=1, microseconds=96764)
```

- Check the first error that occurred:

```python showLineNumbers
print(results.first_error())
```

- Get your data back as a dataframe:

```python showLineNumbers
print(results.collect())
```

### Debug mode

Sometimes you might just want to make sure your code is running correctly before kicking off a large number of jobs. That's what Debug Mode allows you to do:

```python showLineNumbers
results = fused.submit(udf, inputs, debug_mode=True)
```

This will run the first item in `inputs` directly using `fused.run()` (equivalent to `fused.run(udf, inputs[0])`) and then return the results.

### Execution parameters

[`fused.submit()`](/python-sdk/top-level-functions/#fusedsubmit) also have parameters giving you more control over the execution. See the Python SDK [docs page](/python-sdk/top-level-functions/#fusedsubmit) for more details:

- `max_workers`: The number of workers to use for the job pool.
- `engine`: `local` or `remote` (default is `remote`). See [Execution engines](/guide/working-with-udfs/execution/realtime#execution-engines).
- `max_retry`: The maximum number of retries for a job.

## Wall time vs CPU time

There are 2 different runtime calculations for `fused.submit()` jobs:

**Wall time**: Total actual time taken to run the jobs:

```python showLineNumbers
print(results.total_time())
```

**CPU time**: Sum of all the CPU time taken by the jobs. This is the time that counts towards your bill.

```python showLineNumbers
round(sum([t.seconds for t in results.times()]) + sum([t.microseconds for t in results.times()]) / 10e6, 2)
```

## Scaling individual jobs

If individual jobs in your `fused.submit()` need more than 120s or more RAM, use the `instance_type` parameter:

```python showLineNumbers
results = fused.submit(udf, inputs, instance_type="large")
```

This runs jobs on a dedicated batch instance rather than the realtime serverless pool. See [Batch Jobs](/guide/working-with-udfs/execution/batch-jobs) for available instance types and details.

:::note
Using `instance_type` adds startup time but removes the 120s timeout and provides more resources per job.
:::

## Example use cases

[`fused.submit()`](/python-sdk/top-level-functions/#fusedsubmit) is used in many places across our docs:

- üìà Processing 20Tb of data in minutes: [Making a Climate Dashboard](/examples/climate-dashboard) of 20 years of data
- ‚õ¥Ô∏è [Retrieving 30 days](/examples/dark-vessel-detection#33---run-this-udf-over-a-month-of-ais-data) of AIS boat transponder data around the United States to detect illegal fishing
- üõ∞Ô∏è [Retrieving all of Maxar's Open Data STAC Catalogs](/examples/satellite-imagery#preparing-fusedsubmit-to-run-in-parallel) across every events they have imagery for.
