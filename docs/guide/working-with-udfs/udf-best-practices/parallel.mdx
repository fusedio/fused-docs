---
id: parallel
title: How to run in parallel
sidebar_label: How to run in parallel
sidebar_position: 2
---

Need to process hundreds or thousands of inputs? `fused.submit()` runs a UDF over multiple inputs in parallel, spinning up separate instances for each job.

This guide covers best practices for scaling parallel workloads. For the full `fused.submit()` reference, see [Run UDFs in Parallel](/guide/working-with-udfs/run-udfs-in-parallel).

```python
inputs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
results = fused.submit(udf, inputs)
```

## Best practices

### Start small, then scale

Don't immediately spin up 1000 jobs. Test progressively:

```python
# First test with 5 inputs
results = fused.submit(udf, inputs[:5])

# Then 10, then 50, then scale up
results = fused.submit(udf, inputs[:50])
```

### Target 30-45s per job

Each parallel job has a **120s timeout**. Aim for 30-45s per job to leave safety margin for slower runs.

If your jobs consistently hit the timeout, either:
- Break them into smaller chunks
- Use `instance_type` for larger dedicated machines (see [Batch Jobs](/guide/working-with-udfs/udf-best-practices/batch-jobs))

### Test first with debug mode

Run only the first input to verify your setup works:

```python
result = fused.submit(udf, inputs, debug_mode=True)
```

### Check timing

Monitor how long each job takes:

```python
job = fused.submit(udf, inputs[:5], collect=False)
job.wait()
print(job.times())  # Time per job
```

## Error handling

**By default, errors aren't cached.** If a job fails (e.g., API timeout), it will retry fresh on the next run.

However, if you wrap errors in try/except and return a result, that result gets cached:

```python
@fused.udf
def udf(url: str):
    try:
        return fetch_data(url)
    except Exception as e:
        return {"error": str(e)}  # This gets cached!
```

:::tip
Use `ignore_exceptions=True` to skip failed jobs when collecting results:

```python
results = fused.submit(udf, inputs, ignore_exceptions=True)
```
:::

## When to use batch instances

If your jobs need more than 120s or ~4GB RAM, use `instance_type`:

```python
results = fused.submit(
    udf, 
    inputs, 
    instance_type="large",
    collect=False
)
```

See [Batch Jobs](/guide/working-with-udfs/udf-best-practices/batch-jobs) for details on batch instances.

## Example use cases

- [Climate Dashboard](/examples/climate-dashboard) — Processing 20TB of data in minutes
- [Dark Vessel Detection](/examples/dark-vessel-detection#33---run-this-udf-over-a-month-of-ais-data) — Retrieving 30 days of AIS data
- [Satellite Imagery](/examples/satellite-imagery#preparing-fusedsubmit-to-run-in-parallel) — Processing Maxar's Open Data STAC Catalogs

## See also

- [Run UDFs in Parallel](/guide/working-with-udfs/run-udfs-in-parallel) — full `fused.submit()` reference
