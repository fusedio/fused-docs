---
title: To Cloud Storage
sidebar_label: To Cloud Storage
sidebar_position: 2
description: Write data to S3, GCS, and Azure Blob Storage
---

# Writing to Cloud Storage

Fused UDFs can write directly to any cloud storage provider. It's just Python.

---

## How It Works

Any UDF can save files to S3, GCS, Azure, or Fused storage using standard Python libraries:

```python
df.to_parquet("s3://my-bucket/output.parquet")
```

---

## Storage Options

| Storage | URL Prefix | Persistence | Snippets |
|---------|------------|-------------|----------|
| Your S3 bucket | `s3://` | Permanent | [→ Code](/reference/data-writing/#parquet) |
| Fused Storage | `fd://` | Permanent | [→ Code](/reference/data-writing/#parquet) |
| Shared Mount Disk | `/mnt/cache/` | 12 hours | [→ Code](/reference/data-writing/#cloud-optimized-geotiff-cog) |

---

## Fused Storage (`fd://`)

Every user gets managed storage accessible via `fd://`:

```python
username = fused.api.whoami()['handle']
df.to_parquet(f"fd://{username}/my-data/output.parquet")
```

---

## Shared Mount Disk

Files at `/mnt/cache/` are shared across all UDFs in your organization:

```python
df.to_parquet("/mnt/cache/shared_output.parquet")
```

**Note:** Files persist for ~12 hours.

---

## Private Bucket Setup

To write to your own S3 bucket:

1. Add bucket credentials in Workbench → Preferences → Secrets
2. Reference in your UDF

See [Secrets Management](/reference/workbench/preferences#secrets-management) for setup.

---

## Code Examples

- [Parquet snippets](/reference/data-writing/#parquet)
- [GeoTIFF (COG) snippets](/reference/data-writing/#cloud-optimized-geotiff-cog)
- [Large dataset ingestion](/reference/data-writing/#geo-partitioning-with-fusedingest)
