---
sidebar_label: JobPool (class)
title: JobPool (class)
toc_max_heading_level: 2
sidebar_position: 1
---

```python
class JobPool
```

The `JobPool` class manages parallel job execution and result retrieval. It is returned by [`udf.map()`](/python-sdk/api-reference/udf#map).

**Basic usage**

```python
@fused.udf
def my_udf(x: int):
    return x ** 2

# Create a pool of jobs
pool = my_udf.map([1, 2, 3, 4, 5])

# Wait and collect results as DataFrame
df = pool.collect()

# Or get raw results as list
pool.wait()
results = pool.results()  # [1, 4, 9, 16, 25]
```

**Monitoring progress**

```python
pool = my_udf.map(range(100))

# Show live progress
pool.tail()

# Check status
pool.status()        # Series of status counts
pool.all_succeeded() # True if all jobs succeeded
pool.any_failed()    # True if any job failed
```

---

## all_succeeded

```python
pool.all_succeeded() -> bool
```

True if all tasks finished with success.

---

## any_failed

```python
pool.any_failed() -> bool
```

True if any task finished with an error.

---

## any_succeeded

```python
pool.any_succeeded() -> bool
```

True if any task finished with success.

---

## arg_df

```python
pool.arg_df() -> pd.DataFrame
```

The arguments passed to runs as a DataFrame.

---

## cancel

```python
pool.cancel(
    wait=False,  # if True, wait for running tasks to complete
)
```

Cancel any pending (not running) tasks. Note it will not be possible to retry on the same JobPool later.

---

## cancelled

```python
pool.cancelled() -> dict[int, Any]
```

Retrieve the arguments that were cancelled and not run. Results are indexed by position in the args list.

---

## collect

```python
pool.collect(
    ignore_exceptions=False,  # if True, skip failed jobs instead of raising
    flatten=True,             # if True, flatten DataFrame results
    drop_index=False,         # if True, use position index instead of args
) -> pd.DataFrame
```

Wait for all jobs and collect results into a DataFrame.

---

## df

```python
pool.df(
    status_column="status",    # column name for status (None to omit)
    result_column="result",    # column name for result (None to omit)
    time_column="time",        # column name for time (None to omit)
    logs_column="logs",        # column name for logs (None to omit)
    exception_column=None,     # column name for exceptions (None to omit)
    include_exceptions=True,   # include exceptions in result column
) -> pd.DataFrame
```

Get a DataFrame of results as they are currently. Includes columns for each argument passed, plus status, result, time, and logs.

---

## done

```python
pool.done() -> bool
```

True if all tasks have finished, regardless of success or failure.

---

## errors

```python
pool.errors() -> dict[int, Exception]
```

Retrieve the results that are currently done and are errors. Results are indexed by position in the args list.

---

## first_error

```python
pool.first_error() -> Exception | None
```

Retrieve the first (by order of arguments) error result, or `None`.

---

## first_log

```python
pool.first_log() -> str | None
```

Retrieve the first (by order of arguments) logs, or `None`.

---

## logs

```python
pool.logs() -> list[str | None]
```

Logs for each task. Incomplete tasks will be reported as `None`.

---

## n_jobs

The number of jobs in the pool.

---

## pending

```python
pool.pending() -> dict[int, Any]
```

Retrieve the arguments that are currently pending and not yet submitted.

---

## results

```python
pool.results(
    return_exceptions=False,  # if True, return exceptions instead of raising
) -> list[Any]
```

Retrieve all results of the job. Results are ordered by the order of the args list.

---

## results_now

```python
pool.results_now(
    return_exceptions=False,  # if True, return exceptions instead of raising
) -> dict[int, Any]
```

Retrieve the results that are currently done. Results are indexed by position in the args list.

---

## retry

```python
pool.retry()
```

Rerun any tasks in error or timeout states. Tasks are rerun in the same pool.

---

## running

```python
pool.running() -> dict[int, Any]
```

Retrieve the results that are currently running. Results are indexed by position in the args list.

---

## status

```python
pool.status() -> pd.Series
```

Return a Series indexed by status of task counts.

---

## success

```python
pool.success() -> dict[int, Any]
```

Retrieve the results that are currently done and are successful. Results are indexed by position in the args list.

---

## tail

```python
pool.tail(
    stop_on_exception=False,  # if True, stop when first exception occurs
)
```

Wait until all jobs are finished, printing statuses as they become available. Useful for interactively watching the state of the pool.

---

## times

```python
pool.times() -> list[timedelta | None]
```

Time taken for each task. Incomplete tasks will be reported as `None`.

---

## total_time

```python
pool.total_time(
    since_retry=False,  # if True, measure from last retry instead of start
) -> timedelta
```

Returns how long the entire job took. If only partial results are available, returns based on the last task to have been completed.

---

## wait

```python
pool.wait()
```

Wait until all jobs are finished. Use `fused.options.show.enable_tqdm` to enable/disable progress bar.
