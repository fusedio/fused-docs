---
id: quickstart
title: ⚡ Quickstart
sidebar_label: ⚡ Quickstart
sidebar_position: 0
---

# Quickstart: Building a Climate dashboard

We're going to build an interactive dashboard of global temperature data, after processing 1TB of data in < 1min!

### Install `fused`

```python
pip install "fused[all]"
```

Read more about installing Fused [here](/python-sdk/#python-install).

<details>
<summary>Authenticate in Fused</summary>

In a notebook:

```python
from fused.api import NotebookCredentials

credentials = NotebookCredentials()
print(credentials.url)
```

Follow the link to authenticate.

Read more about [authenticating in Fused](/python-sdk/authentication/).

</details>

### 1 month of mean temperature

```python
import fused
```

We'll save this data to a file in your Fused S3 bucket. Find your username with: `fused.api.whoami()['handle']`. 

Change the output directory to your own S3 bucket:
{/* TODO: Any faster / better way to get this? */}

```python
output_dir = f"s3://fused-users/fused/{fused.api.whoami()['handle']}/climate_data_monthly_means/"
```

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs className="unique-tabs">
  <TabItem value="DuckDB">
    ```python
    @fused.udf
    def udf(
        month: str = "2024-01",
    ):
        import duckdb
        result = duckdb.sql(f"""
          SELECT 
              datestr::VARCHAR as datestr,
              ROUND(AVG(daily_mean), 2) as daily_mean_temp
          FROM 's3://fused-asset/data/era5/t2m/datestr={month}-*/*.parquet'
          GROUP BY datestr
          ORDER BY datestr
        """).df()

        output_fp = fused.file_path(f"monthly_climate/{month}.pq")
        result.to_parquet(output_fp)
        
        return result
    ```
  </TabItem>
  <TabItem value="Pandas">

    NOTE: `pandas` approach is a bit slower than DuckDB.

    ```python
    @fused.udf
    def udf(month: str = "2024-01",):
        import pandas as pd

        files = fused.api.list(f"s3://fused-asset/data/era5/t2m/datestr={month}-")

        dfs = [pd.read_parquet(file, columns=['daily_mean']).assign(datestr=file.split('datestr=')[1].split('/')[0]) for file in files]
        result = pd.concat(dfs).groupby('datestr')['daily_mean'].mean().round(2).reset_index()

        output_fp = fused.file_path(f"monthly_climate/{month}.pq")
        result.to_parquet(output_fp)
        
        return result
    ```

  </TabItem>
</Tabs>

Run this UDF on Fused server:

```python
fused.run(udf)
```

```
   datestr     daily_mean_temp
3  2024-01-04            277.36
4  2024-01-05            277.26
5  2024-01-06            277.17
```

### Computing mean daily temperature for 1950-1959 (33.5Gb in 1min!)

Explore the available data for yourself in [File Explorer](https://www.fused.io/workbench/files?path=s3%3A%2F%2Ffused-asset%2Fdata%2Fera5%2Ft2m_daily_mean_v31%2F)

We'll process 10 years of data:

```python
import pandas as pd
dates = pd.date_range('1950-01-01', '1959-12-31').strftime('%Y-%m-%d').tolist()
```

We can now run our previous UDF in parallel across 1,000 jobs:

```python
results = fused.submit(udf, dates, max_workers=1000, collect=False)
```

Tail the logs as the jobs run:

```python
results.tail()
```

See how long all the jobs took:

```python
results.total_time()
```

```bash
datetime.timedelta(seconds=67, microseconds=896063)
```

We just processed 10 years of worldwide global data in **1min 7s**!

Daily values are a bit too granular, let's instead get the monthly mean temperature:

```python
@fused.udf
def udf():
   common = fused.load("https://github.com/fusedio/udfs/tree/7918aff/public/common/").utils
   con = common.duckdb_connect()
   
   daily_temp_files = fused.api.list(f"s3://fused-users/fused/{fused.api.whoami()['handle']}/climate_data_all_same_col/")
   # daily_temp_files = daily_temp_files[:100]
   
   file_list = "', '".join(daily_temp_files)
   
   result = con.sql(f"""
       SELECT LEFT(REGEXP_EXTRACT(REGEXP_EXTRACT(filename, '[^/]+$'), '([0-9]{{4}}-[0-9]{{2}}-[0-9]{{2}})'), 7) as month,
              ROUND(AVG(mean_temp), 2) as monthly_mean_temp
       FROM read_parquet(['{file_list}'], filename=True)
       GROUP BY month
       ORDER BY month
   """).df()
   
   return result
```

We can now open this UDF in Workbench, Fused's web-based IDE:

```python
# Save to Fused
udf.to_fused("monthly_mean_temp_since_1950")

# Load again to get the Workbench URL
loaded_udf = fused.load("monthly_mean_temp_since_1950")
```

In a notebook returning the loaded UDF will give you a hyperlink `Workbench URL`:

```python
loaded_udf
```

Click on the link to open the UDF in Workbench. Click "+ Add to UDF Builder" 

You can now build a new Frame in Workbench.

{/* TODO: Add screenshots of Workbench */}




