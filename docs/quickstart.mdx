---
id: quickstart
title: ⚡ Quickstart
sidebar_label: ⚡ Quickstart
sidebar_position: 0
---

# Quickstart: Building a Climate dashboard

We're going to build an interactive dashboard of global temperature data, after processing 1TB of data in < 1min!

### Install `fused`

```python
pip install "fused[all]"
```

Read more about installing Fused [here](/python-sdk/#python-install).

<details>
<summary>Authenticate in Fused</summary>

In a notebook:

```python
from fused.api import NotebookCredentials

credentials = NotebookCredentials()
print(credentials.url)
```

Follow the link to authenticate.

Read more about [authenticating in Fused](/python-sdk/authentication/).

</details>

### Processing 1 month

{/* TODO: Have link to ingestion pipeline later on */}
[ERA5](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5) data was ingested using Fused ingestion pipeline.

```python
import fused
```

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs className="unique-tabs">
  <TabItem value="DuckDB">
    ```python
    @fused.udf
    def udf(
        month: str = "2024-01",
    ):
        import duckdb
        result = duckdb.sql(f"""
          SELECT 
              datestr::VARCHAR as datestr,
              ROUND(AVG(daily_mean), 2) as daily_mean_temp
          FROM 's3://fused-asset/data/era5/t2m/datestr={month}-*/*.parquet'
          GROUP BY datestr
          ORDER BY datestr
        """).df()

        output_fp = fused.file_path(f"monthly_climate/{month}.pq")
        result.to_parquet(output_fp)
        
        return result
    ```
  </TabItem>
  <TabItem value="Pandas">

    NOTE: `pandas` approach is a bit slower than DuckDB.

    ```python
    @fused.udf
    def udf(month: str = "2024-01",):
        import pandas as pd

        files = fused.api.list(f"s3://fused-asset/data/era5/t2m/datestr={month}-")

        dfs = [pd.read_parquet(file, columns=['daily_mean']).assign(datestr=file.split('datestr=')[1].split('/')[0]) for file in files]
        result = pd.concat(dfs).groupby('datestr')['daily_mean'].mean().round(2).reset_index()

        output_fp = fused.file_path(f"monthly_climate/{month}.pq")
        result.to_parquet(output_fp)
        
        return result
    ```

  </TabItem>
</Tabs>

Run this UDF on Fused server (the compute happens on the Fused server, regardless of where you call this):

```python
fused.run(udf)
```

```
   datestr     daily_mean_temp
3  2024-01-04            277.36
4  2024-01-05            277.26
5  2024-01-06            277.17
```

### 20 years of data (1TB in < 1min!)

Explore the available data for yourself in [File Explorer](https://www.fused.io/workbench/files?path=s3%3A%2F%2Ffused-asset%2Fdata%2Fera5%2Ft2m%2F)

We'll process 20 years of data:

```python
available_days = fused.api.list('s3://fused-asset/data/era5/t2m/')
available_months = list(set([path.split('datestr=')[1][:7] for path in available_days]))
recent_months = [month for month in available_months if int(month[:4]) >= 2005]
```

<details>
<summary>Size of data quick calculation</summary>

Each file being about 140MB a quick back of the envelope calculation gives us:
```python
recent_days = [day for day in available_days if day.split('datestr=')[1][:7] in recent_months]
len(recent_days) * 140 / 1000 # size in GB of files we'll process
```

```bash
1005.62
```
</details>

We're looking at 1TB of data!

Fused allows us to run a UDF in parallel. So we'll process 1 month of data across 1k jobs:

```python
results = fused.submit(
  udf, 
  recent_months, 
  max_workers=1000, 
  collect=False
)
```

Tail the logs as the jobs run:

```python
results.tail()
```

See how long all the jobs took:

```python
results.total_time()
```

```bash
datetime.timedelta(seconds=40, microseconds=437845)
```

**We just processed 20 years of worldwide global data, over 1TB in 40s!!**

All we need to do now is aggregate the data by month:

```python
@fused.udf(cache_max_age='0s')
def udf():
    import duckdb
    
    monthlys = fused.api.list(fused.file_path(f"monthly_climate/"))
    file_list = "', '".join(monthlys)
    
    result = duckdb.sql(f"""
       SELECT 
           LEFT(datestr, 7) as month,
           ROUND(AVG(daily_mean_temp), 2) as monthly_mean_temp
       FROM read_parquet(['{file_list}'])
       GROUP BY month
       ORDER BY month
    """).df()
    
    return result
```

Let's do this in Workbench, Fused's web-based IDE:

```python
# Save to Fused
udf.to_fused("monthly_mean_temp")

# Load again to get the Workbench URL
loaded_udf = fused.load("monthly_mean_temp")
```

In a notebook returning the loaded UDF will give you a hyperlink `Workbench URL`:

```python
loaded_udf
```

Click on the link to open the UDF in Workbench. Click "+ Add to UDF Builder" 

{/* TODO: Add a screenshot of Table view in Wb */}


