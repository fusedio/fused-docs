---
title: Quickstart for Data Scientists
sidebar_label: Data Scientist
sidebar_position: 1
description: Get started with Fused for data science workflows
---

# Quickstart for Data Scientists

Build analysis workflows with Jupyter, run experiments, and share results.

## Setup

Go to [Workbench](https://www.fused.io/workbench) to start making your first [User Defined Function (UDF)](/guide/running-udfs/writing-udfs).

## Your First Analysis UDF

```python
@fused.udf
def udf(threshold: float = 0.5):
    import pandas as pd
    
    # Load sample data
    df = pd.read_csv("s3://fused-sample/demo_data/housing_2024.csv")
    
    # Process
    df['price_per_sqft'] = df['price'] / df['area']
    df['above_threshold'] = df['price_per_sqft'] > threshold
    
    return df
```

## Visualize in Workbench

1. Open [Workbench](https://www.fused.io/workbench)
2. Create a new UDF
3. Paste your code
4. See results in the data table

## Key Patterns

### Cache Expensive Operations

```python
@fused.udf
def udf():

    @fused.cache
    def load_data():
        import pandas as pd
        return pd.read_csv("s3://bucket/data.csv")
    
    df = load_data()  # Next time you call this UDF, loading will be much faster as this function is cached
    df['new_col'] = df['some_col'] * 2
    return df
```

### Experiment Tracking

```python
@fused.udf
def experiment(learning_rate: float = 0.01, epochs: int = 100):
    # Train model with parameters
    model = train(lr=learning_rate, epochs=epochs)
    return {"accuracy": model.accuracy, "loss": model.loss}

# Grid search
params = [{"learning_rate": lr, "epochs": e} 
          for lr in [0.01, 0.1] 
          for e in [50, 100]]
results = fused.submit(experiment, params)
```

## Next Steps

- [Loading Data](/guide/loading-data/) - Read from S3, databases
- [Caching](/core-concepts/cache/) - Speed up analysis
- [Scaling Up](/guide/scaling-up/) - Parallel processing
