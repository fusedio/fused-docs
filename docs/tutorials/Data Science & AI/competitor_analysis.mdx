---
slug: competitor-analysis
title: "Competitor Store Location Analysis"
---

This tutorial will:
- Explore the location of 2 store chains in Sacramento, CA
{/* TODO: Better word for catchment */}
- Create catchments of drive time around each store
- Join catchments with census data (population, average income)
- Determine which of our stores are most effective at reaching the target population, with the least competition. 

:::info Using AI prompts as a starting point

This tutorial will show you what prompts we're using to build this analysis. 

Note that since AI is not deterministic, the prompts may not always work the same way. You might need to do some manual changes to the prompts or to the code to get it working. 

Consider the prompts as a starting point, but not the final answer.
:::

## Getting Data

We're going to use datasets we found online to this analysis. We'll consider:
- Starbucks point locations as our target stores. [Available on Kaggle](https://www.kaggle.com/datasets/starbucks/store-locations)
- McDonald's point locations as our competitor stores. [Available on Kaggle](https://www.kaggle.com/datasets/ben1989/mcdonalds-locations)
- Census Data to get population and average income of the area around each store.

### Starbucks & McDonalds locations

We can ask the AI to write a UDF to load these from the Kaggle `cURL` api:

![Downloading Starbucks data from Kaggle](../../../static/img/tutorials/data-science-ai/starbucks_kaggle_download.png)

```text
Open this specific dataset and return points as a dataframe based on this Kaggle curl request:

#!/bin/bash
curl -L -o ~/Downloads/store-locations.zip\
  https://www.kaggle.com/api/v1/datasets/download/starbucks/store-locations
```

In order to simplify this tutorial we've already downloaded the data and saved it to a bucket in Fused:

- Starbucks: `s3://fused-sample/demo_data/catchment_analysis/starbucks_location.pq`
- McDonalds: `s3://fused-sample/demo_data/catchment_analysis/macdonalds_location.pq`

### Census Data

You can get all the relevant Census Data on the official [US Census website](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html). 

For simplicity however we've also already downloaded the data and made it available. We'll be looking at [Census Block Groups](https://en.wikipedia.org/wiki/Census_block_group) (BG) data for this analysis

- Sacramento, CA Census Block Groups: `s3://fused-users/fused/max/demos/california_population/acs_bg_ca_2022_sacramento_geoparquet.parquet`

## Exploring Data directly in Fused

We recommend you make 1 UDF for each dataset so you can explore them individually as layers on the [Map View](/workbench/udf-builder/map/). 

### Starbucks

Make a new UDF and ask the AI:

```text
can you open this starbucks location file (s3://fused-users/fused/max/demos/catchment_analysis/starbucks_sacramento.pq) and return as geodataframe 
```

### McDonalds

Make another new UDF and ask the AI:

```text
can you open this macdonalds location file (s3://fused-users/fused/max/demos/catchment_analysis/mcdonalds_sacramento.pq) and return as geodataframe 
```

### Census Data

Make another new UDF and ask the AI:

```text
Can you open this file using geopandas as return df s3://fused-users/fused/max/demos/california_population/acs_bg_ca_2022_sacramento_geoparquet.parquet
```

Renaming each UDF to their respective names and changing the color of each store in the [Visualization Tab](/workbench/udf-builder/styling/) to something more visible we get:

<details>
<summary>Visualization JSONs</summary>

You can copy paste these JSONs into the [Visualization Tab](/workbench/udf-builder/styling/) to have similar colored stores:

**Starbucks**

```
{
  "vectorLayer": {
    "@@type": "GeoJsonLayer",
    "stroked": true,
    "filled": false,
    "pickable": true,
    "lineWidthMinPixels": 1,
    "pointRadiusMinPixels": 1,
    "getLineColor": {
      "@@function": "colorContinuous",
      "attr": "value",
      "domain": [
        0,
        10
      ],
      "steps": 20,
      "colors": "Mint",
      "nullColor": [
        2,
        250,
        1
      ]
    },
    "getFillColor": [
      208,
      208,
      208,
      40
    ]
  }
}
```

**McDonalds**

```
{
  "vectorLayer": {
    "@@type": "GeoJsonLayer",
    "stroked": true,
    "filled": false,
    "pickable": true,
    "lineWidthMinPixels": 1,
    "pointRadiusMinPixels": 1,
    "getLineColor": {
      "@@function": "colorContinuous",
      "attr": "value",
      "domain": [
        0,
        10
      ],
      "steps": 20,
      "colors": "Burg",
      "nullColor": [
        250,
        100,
        1
      ]
    },
    "getFillColor": [
      208,
      208,
      208,
      40
    ]
  }
}
```

</details>

![Stores and Census Block Groups in Sacramento](../../../static/img/tutorials/data-science-ai/stores_and_block_groups.png)


## Creating isochrones

The Fused [AI Assistant](/workbench/ai-assistant/) can take other UDFs in context to use as inpsiration to adapt existing code to a new use case.

We're going to open the [Get Isochrone UDF](https://www.fused.io/workbench/udf/catalog/Get_Isochrone-15dcecd8-c401-42a8-b9f0-a9dac3d7ddc3) and use this one as inspiration for the AI. This UDF:
- Uses the [Valhalla API](https://valhalla.github.io/valhalla/api/isochrone/api-reference/) to create isochrone of drive time around a point
- Returns a GeoDataFrame with the isochrone polygons

This is exactly what we want to do for our Starbucks points! The parameters we want for this analysis are:
- 15min 
- drive time (`auto` [costing mode](https://valhalla.github.io/valhalla/api/turn-by-turn/api-reference/#costing-models))

However this API can take a lot of time to run, so we're going to break our problem down:
1. Ask the AI to use the `Get_Isochrone` UDF but only for 3 points to start
2. Validate that isochrones look correct
3. Manually increase the number of calls to the API we'll do.



To start:
- Open the [`Get_Isochrone` UDF](https://www.fused.io/workbench/udf/catalog/Get_Isochrone-15dcecd8-c401-42a8-b9f0-a9dac3d7ddc3) in Workbench. You don't need to make a copy but you need to have it opened.
- Go into the chat for your `starbucks_location` UDF. 
- Make sure to write `@Get_Isochrone` in the AI request so the AI adds that UDF to its context.

Ask the AI (in the chat for your `starbucks_location` UDF):
```text
Use @Get_Isochrone to create 15-minute driving isochrones around each starbucks location. 

Test this out with just 3 points first so we make sure this is working correctly at first
```

You can then visually see on the map we get 3 isochrones:

import LazyReactPlayer from '@site/src/components/LazyReactPlayer'

<LazyReactPlayer
  url="https://fused-magic.s3.us-west-2.amazonaws.com/workbench-walkthrough-videos/docs_rewrite/tutorials/catchments_from_get_isochrone_compressed.mp4"
  width="100%"
  height="100%"
  controls={true}
  playing={false}
/>


We'll leave it up to you to manually increase the number of calls if you'd like to. But for simplicity we also provide the output directly as a file:

`s3://fused-users/fused/max/demos/catchment_analysis/starbucks_isochrones_15min.pq`

## Joining catchments & census data

Next we're going to:
- Join the filtered McDonald and Starbucks points to Sacramento block groups polygon layer, counting
- Total McDonalds and Starbucks stores per block group
- Take each store’s **15-minute drive-time catchment polygon** and finds which **block groups** it intersects.

- From those intersecting BGs, we'll compute catchment-level metrics:
    - **Population** inside the catchment as pop_sum , use
    - **Median income**
    - **Block Group count** (number of intersecting block groups by the catchment area)

**Asking AI**

In a new UDF:

```text
Write a UDF that intersects each store’s 15-minute catchment polygon (from catchment_udf) with Sacramento block groups.  
For each store, use gpd.overlay to compute:  
- Total population (sum across intersecting block groups)  
- Median household income (median of intersecting block groups)  
- Block group count (distinct GEOIDs touched)  
Aggregate results per store into a clean summary table and return that.

The block groups for sacramento are here: `s3://fused-users/fused/max/demos/catchment_analysis/sacramento_block_groups.pq`

The starbucks catchments are here: `'s3://fused-users/fused/max/demos/catchment_analysis/starbucks_isochrones_15min.pq'`

use 4326 projection for all
Return the catchment geometries so I can still visualize the gdf on a map
```

## Competitor Analysis

In the same UDF, we can ask the AI to do a competitor analysis:

```text
Enhance the catchment UDF to measure competition:  
- Load McDonald’s store locations from  
  `s3://fused-users/fused/max/demos/catchment_analysis/mcdonalds_sacramento.pq`.  
- For each Starbucks 15-minute catchment polygon, count how many McDonald’s points fall inside (point-in-polygon).  
- Add this as a new column `Competition` to the per-store summary table.  
How many mcdonalds (competitor to starbucks in this case) are present in each catchment?
```

We also want to keep track of how many of *our own stores* are present in each catchment:

```text
Enhance the catchment UDF to measure cannibalization:  
- Load Starbucks store locations from  
  `s3://fused-users/fused/max/demos/catchment_analysis/starbucks_sacramento.pq`.  
- For each Starbucks 15-minute catchment polygon, count how many *other* Starbucks points fall inside (exclude the store itself).  
- Add this as a new column `Cannibalization` to the per-store summary table.  
```

## Ranking stores

Finally, we want to rank the stores based on:
- Highest amount of population in the catchment
- Highest median income in the catchment
- Lowest competition
- Lowest cannibalization (i.e. number of our own stores)

So let's ask the AI:

```text
Based on all the info here, give me a ranking of which stores I should invest in the most. I care about starbucks stores that have:
- The highest income 
- Highest population
- Least amount of competitors
- Least amount of cannibilization

Come up with a formula for ranking the starbucks stores based on this
```

You can then ask the AI to plot a chart for you. When your UDF returns a dataframe, the AI chat will suggest making a chart:

![AI suggesting to create a chart from the dataframe](../../../static/img/tutorials/data-science-ai/create_a_chart.png)

Which helps visualize the results:

![Starbucks location ranking showing population, income, competition and cannibalization metrics](../../../static/img/tutorials/data-science-ai/starbucks_location_ranking.png)

Our AI gave as a ranking showing where top stores tend to have:
- Highest income
- Lowest population

The good thing about Fused is all the AI output is Python code, we could dive into exactly how the ranking is done and fine tune ourselves!

## Next Steps

Here are some ideas of improvements you could make:
- Fine tune specific analysis elements like ranking, isochrone drive times, etc. 
- Find more data sources to refine the analysis.
- Scale to the entire US using [`fused.submit()`](/core-concepts/run-udfs/run-small-udfs/#running-jobs-in-parallel-fusedsubmit).
