# Read Data

Common examples for reading geospatial data in Fused.

## Python Packages

### `geopandas`

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/subway_stations.geojson"):
    import geopandas as gpd
    
    return gpd.read_file(path)
```

### `shapely`

```python
@fused.udf
def udf():
    import geopandas as gpd
    from shapely.geometry import Point, Polygon
    
    # Create geometries with shapely
    points = [Point(-122.4, 37.8), Point(-122.3, 37.7)]
    polygon = Polygon([(-122.5, 37.7), (-122.3, 37.7), (-122.3, 37.9), (-122.5, 37.9)])
    
    gdf = gpd.GeoDataFrame(
        {'type': ['point', 'point', 'polygon']},
        geometry=points + [polygon],
        crs=4326
    )
    
    return gdf
```

### `duckdb`

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/housing_2024.parquet"):
    import duckdb
    
    conn = duckdb.connect()
    result = conn.execute(f"""
        SELECT * 
        FROM '{path}'
        WHERE latitude IS NOT NULL
        LIMIT 1000
    """).df()
    
    return result
```

### `rioxarray`

{/* TODO: Missing data in S3 */}

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/elevation.tif"):
    import rioxarray as rxr
    
    # Read raster data with rioxarray
    raster = rxr.open_rasterio(path)
    
    # Convert to DataFrame for display
    df = raster.to_dataframe().reset_index()
    
    return df.head(1000)
```

### `xarray`

```python
@fused.udf
def udf():
    import xarray as xr
    
    # Download NetCDF data to mount disk for proper reading
    path = fused.download('s3://fused-sample/demo_data/2025_01_01_ERA5_surface.nc','2025_01_01_ERA5_surface.nc')
    ds = xr.open_dataset(path)
    
    # Convert to DataFrame
    df = ds.to_dataframe().reset_index()
    
    return df.head(1000)
```

## Table Formats (Vector)

### GeoJSON (.geojson, .json)

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/subway_stations.geojson"):
    import geopandas as gpd
    
    return gpd.read_file(path)
```

### Shapefile (.shp + .shx, .dbf, .prj)

{/* TODO: Missing data in S3 */}
{/* TODO: Also check this would actually work */}

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/counties.shp"):
    import geopandas as gpd
    
    return gpd.read_file(path)
```

### GeoPackage (.gpkg)

{/* TODO: Missing data in S3 */}

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/buildings.gpkg"):
    import geopandas as gpd
    
    return gpd.read_file(path)
```

### KML/KMZ (.kml, .kmz)

{/* TODO: Missing data in S3 */}

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/routes.kml"):
    import geopandas as gpd
    
    # Enable KML driver
    return gpd.read_file(path, driver='KML')
```

### GML (.gml)

{/* TODO: Missing data in S3 */}

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/parcels.gml"):
    import geopandas as gpd
    
    return gpd.read_file(path)
```

### File Geodatabase (.gdb)

{/* TODO: Missing data in S3 */}

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/city_data.gdb"):
    import geopandas as gpd
    
    # List available layers
    layers = gpd.list_layers(path)
    print(f"Available layers: {layers}")
    
    # Read specific layer
    return gpd.read_file(path, layer=0)
```

### PostGIS (database)

{/* TODO: Missing data in S3 */}

```python
@fused.udf
def udf():
    import geopandas as gpd
    from sqlalchemy import create_engine
    
    # Connection string (use environment variables for credentials)
    conn_string = "postgresql://user:password@host:port/database"
    
    engine = create_engine(conn_string)
    gdf = gpd.read_postgis(
        "SELECT * FROM public.my_table LIMIT 1000", 
        engine, 
        geom_col='geometry'
    )
    
    return gdf
```

### FlatGeobuf (.fgb)

{/* TODO: Missing data in S3 */}

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/roads.fgb"):
    import geopandas as gpd
    
    return gpd.read_file(path)
```

### Parquet (.parquet)

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/buildings.parquet"):
    import geopandas as gpd
    
    return gpd.read_parquet(path)
```

### CSV with coordinates (.csv)

{/* TODO: Missing data in S3 */}
{/* TODO: Use NYC examples */}

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/points.csv"):
    import pandas as pd
    import geopandas as gpd
    from shapely.geometry import Point
    
    # Read CSV
    df = pd.read_csv(path)
    
    # Convert to GeoDataFrame
    gdf = gpd.GeoDataFrame(
        df, 
        geometry=gpd.points_from_xy(df.longitude, df.latitude),
        crs=4326
    )
    
    return gdf
```

### Excel (.xlsx)

{/* TODO: Missing data in S3 */}
{/* TODO: Use NYC examples */}

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/locations.xlsx"):
    import pandas as pd
    import geopandas as gpd
    from shapely.geometry import Point
    
    # Read Excel file
    df = pd.read_excel(path)
    
    # Convert to GeoDataFrame if coordinates exist
    if 'longitude' in df.columns and 'latitude' in df.columns:
        gdf = gpd.GeoDataFrame(
            df,
            geometry=gpd.points_from_xy(df.longitude, df.latitude),
            crs=4326
        )
        return gdf
    
    return df
```

{/* TODO: Add back after moving this in */}
{/* ### WMS Tile

For WMS tiles, see the dedicated [WMS Tile tutorial](/tutorials/others/in/wmstile/). */}

## Array Formats (Raster)

### GeoTIFF (.tif, .tiff)

```python
@fused.udf
def udf(
    path: str = 's3://fused-sample/demo_data/satellite_imagery/wildfires.tiff'
):
    import rasterio

    with rasterio.open(path) as src:
        data = src.read()
        bounds = src.bounds

    return data, bounds
```

### NetCDF (.nc)

```python
@fused.udf
def udf():
    import xarray as xr
    
    # Download to mount disk for proper NetCDF reading
    path = fused.download('s3://fused-sample/demo_data/climate_data.nc', 'climate_data.nc')
    
    # Open NetCDF dataset
    ds = xr.open_dataset(path)
    
    return ds.to_dataframe().reset_index().head(1000)
```

{/* ### HDF5 (.h5, .hdf5)

```python
@fused.udf
def udf():
    import h5py
    import numpy as np
    import pandas as pd
    
    # Download HDF5 file
    path = fused.download('s3://fused-sample/demo_data/satellite.h5', 'satellite.h5')
    
    with h5py.File(path, 'r') as f:
        # List available datasets
        datasets = list(f.keys())
        
        # Read first dataset
        data = f[datasets[0]][:]
        
    return pd.DataFrame({'dataset': datasets, 'shape': [str(data.shape)]})
``` */}

{/* ### JPEG2000 (.jp2)

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/landsat.jp2"):
    import rioxarray as rxr
    
    # Read JPEG2000 file
    raster = rxr.open_rasterio(path)
    
    return raster.values, raster.bounds()
``` */}

{/* ### Zarr (.zarr)

```python
@fused.udf
def udf(path: str = "s3://fused-sample/demo_data/climate.zarr"):
    import xarray as xr
    
    # Open Zarr dataset
    ds = xr.open_zarr(path)
    
    # Convert to DataFrame
    df = ds.to_dataframe().reset_index()
    
    return df.head(1000)
``` */}

### STAC Catalog

#### Earth on AWS

```python
@fused.udf
def udf(
    bounds: fused.types.Bounds = [-77.083, 38.804, -76.969, 38.983],
):
    import odc.stac
    import pystac_client
    import planetary_computer

    odc.stac.configure_s3_access(aws_unsigned=True)
    catalog = pystac_client.Client.open("https://earth-search.aws.element84.com/v1")

    # Loading Elevation model
    items = catalog.search(
        collections=["cop-dem-glo-30"], 
        bbox=bounds
    ).item_collection()

    xarray_dataset = odc.stac.load(
        items,
        crs="EPSG:3857",
        bands=["data"],
        resolution=150,
        bbox=bounds,
    ).astype(int)

    return xarray_dataset["data"], bounds
```

#### Microsoft Planetary Computer

```python
@fused.udf
def udf(
    bounds: fused.types.Bounds = [-122.463,37.755,-122.376,37.803],
):
    import odc.stac
    import planetary_computer
    import pystac_client
    
    catalog = pystac_client.Client.open(
        "https://planetarycomputer.microsoft.com/api/stac/v1",
        modifier=planetary_computer.sign_inplace,
    )

    # Loading Elevation model
    items = catalog.search(collections=["cop-dem-glo-30"],bbox=bounds).item_collection()
    
    xarray_dataset = odc.stac.load(
        items,
        crs="EPSG:3857",
        bands=["data"],
        resolution=150,
        bbox=bounds,
    ).astype(int)
    
    return xarray_dataset["data"], bounds
``` 