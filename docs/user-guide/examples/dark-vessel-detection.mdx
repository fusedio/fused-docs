---
sidebar_label: "End-to-end Example: Dark Vessel Detection"
title: "End-to-end Example: Dark Vessel Detection"
tags: ['example', 'sentinel 1', 'raster', 'vector', 'ingestion']
sidebar_custom_props:
    name: "End-to-end example: Dark Vessel Detection"
    image: 'https://fused-magic.s3.us-west-2.amazonaws.com/thumbnails/udfs-staging/Fused_Logo.png'
    url: "/user-guide/examples/dark-vessel-detection"
    urlTS: "/user-guide/examples/dark-vessel-detection"
    description: 'Using Sentinel 1 radar images + AIS ship data to detect potential illegal ship activity'
---

_A complete example show casing how to use Fused to ingest data into a geo-partitioned, cloud friendly format, process images & vectors and use UDFs to produce an analysis_

:::note
    This tutorial assumes you have [access to Fused](/user-guide/login/) & [installed the `fused` Python package](/python-sdk/#install) locally
:::

## 1. The problem: Detecting illegal boats

{/* Start by showing what the end result looks like: "this is what we're going to do in this example"*/}

Monitoring what happens at sea isn't the easiest task. Shores are outfitted with radars and each ship has a transponder to publicly broadcast their location (using [Automatic Identification System, AIS](https://en.wikipedia.org/wiki/Automatic_identification_system)), but ships sometimes want to hide their location when taking part in illegal activities. 

Global Fishing Watch [has reported on "dark vessels"](https://globalfishingwatch.org/research-project-dark-vessels/) comparing Sentinel 1 radar images to public AIS data and matching the two to compare where boats report being versus where they _actually_ are. 

In this example, we're going to showcase a basic implementation of a similar analysis to identify _potential_ dark vessels, all in Fused.

import ImageWorkflow from '@site/docs/user-guide/examples/dark_vessel_methodology.png';

<div style={{textAlign: 'center'}}>
<img src={ImageWorkflow} alt="Dark Vessel Detection workflow" style={{width: 1000}} />
</div>

Here's the result of our analysis, running in real time in Fused:

import ReactPlayer from 'react-player'

{/* <ReactPlayer playsinline={true} className="video__player" playing={true} muted={true} controls height="100%" url="https://fused-magic.s3.us-west-2.amazonaws.com/workbench-walkthrough-videos/docs_rewrite/examples/dark-vessel-detection/output_analysis_S1_ais.mp4" width="100%" /> */}
<ReactPlayer playsinline={true} className="video__player" playing={true} muted={true} controls height="100%" url="https://fused-magic.s3.us-west-2.amazonaws.com/workbench-walkthrough-videos/docs_rewrite/examples/dark-vessel-detection/analysis_walkthrough_dark_vessel_detection.mp4" width="100%" />

{/* Need more context around how the analysis is done */}

Here are the steps we'll produce:
- Getting Sentinel 1 radar images over our Area of Interest and within our Time of Interest
- Run a simple algorithm to detect bright spots in radar images -> Return boats outline
- Fetch AID data over the same Area & Time of Interest
- Merge the 2 datasets together
- Keep boats that appear in Sentinel 1 but not in AIS -> Those are our potential Dark Vessels.

import ImageDataPipeline from '@site/docs/user-guide/examples/dark_vessel_data_breakdown.png';

<div style={{textAlign: 'center'}}>
<img src={ImageDataPipeline} alt="Dark Vessel Detection data pipeline" style={{width: 1000}} />
</div>


:::note
    This is crude analysis, mostly meant to demonstrate some of the major components of Fused, not to expose any dark vessels. The analysis has some major limitations and itself should be taken with a grain of salt. 
    
    That being said, we encourage you to use it as a starting point for your own work!
:::



## 2. Data for our analysis

We need 2 main datasets:
- [Sentinel 1 radar images](https://sentinel.esa.int/web/sentinel/copernicus/sentinel-1)
- [AIS data](https://en.wikipedia.org/wiki/Automatic_identification_system)

Both of which are free & open data sources. Since we want our analysis to take only a few seconds at most to run our data needs to be **fast to read** & **scalable to access**.

{/* Need a link towards cloud native so people can read more about this somewhere else */}
This is why we want both of our datasets to in a Cloud Native format. At the highest level and in practice this means that our data is:
- On a cloud storage (i.e. on S3 buckets)
- In a format that's fast to read and allows loading only small areas at a time ([Cloud Optimized GeoTiff](https://cogeo.org/) or [GeoParquet](https://geoparquet.org/))

{/* Need a blogpost / docs page about "why cloud native" or something along those lines */}

After looking around at different options we're going to use:
- Sentinel 1 data from the [Microsoft Planetary Computer Data Catalog](https://planetarycomputer.microsoft.com/dataset/sentinel-1-grd)

    For the nerds out there, we're using the Ground Range Detected product, not the [Radiometrically Terrain Corrected](https://planetarycomputer.microsoft.com/dataset/sentinel-1-rtc) because we're looking at boats in the middle of the ocean, so terrain shouldn't be any issue.
    - This dataset is available as Cloud Optimized GeoTiff through a [STAC Catalog](https://stacspec.org/en/), meaning we can directly use this data as is.

- AIS data from the [NOAA Digital Coast](https://www.coast.noaa.gov/digitalcoast/tools/ais.html). We have data all around the continental US [per day as individual `.zip` files](https://coast.noaa.gov/htdata/CMSP/AISDataHandler/2024/index.html)
    - This dataset is not in a cloud native format. If we were to use this directly, every time we were to make a change to our analysis or look at a new area we'd have to find the correct `.zip` file, decompress it, read the entire AIS data for any given day then query only around our area of interest. This is possible, but brings out iteration speed from seconds to minutes.

import ImgAISNoaa from '@site/docs/user-guide/examples/AIS_noaa_coast_portal.png';

<div style={{textAlign: 'center'}}>
<img src={ImgAISNoaa} alt="Dark Vessel Detection data pipeline" style={{width: 600}} />
</div>

## 3. Ingesting AIS data

{/* 
Topics:
- Sentinel 1 already in COG + STAC -> No need to do ingest it ourselves
- AIS is in zip files on a server somewhere -> we're going to re-ingest it ourselves to make it cloud native (i.e. on cloud on S3 bucket) + geo-partitioned (i.e. in a format that's fast to read - parquet + chunked accordingly) 
 */}

Since our AIS dataset is not in a geo-partitioned, cloud native format, our first step is to ingest it into a tiled format and put it on a cloud bucket. Thankfully we can do all of this in Fused.

By the end of this ingestion process we'll have:
- AIS data for 2024 on a cloud storage (AWS S3 bucket)
- In a GeoParquet format so it's fast to read
- Tiled & Chunked so we can read only a small portion at a time, making it even faster

To get this done we'll:
1. Get a location to store our partitioned AIS data on (this can be any AWS S3 bucket, we'll use one managed by Fused to make this simpler)
{/* Link to UDF docs */}
2. Write a simple UDF to unzip each AIS data over a given date range, read it and save it as a parquet file on S3
{/* Link to batch job doc */}
3. Run this UDF as a batch job to run this across all of the 2024 AIS archive
4. Ingest all of the monthly AIS `.parquet` files into geo-partitioned files to speed up their read time over small areas

### 3.1 - Deciding on where to store out partitioned data

We first need to unzip & read our AIS data before ingesting in as a geo-partitioned cloud native format. One simple way to do this is to write a UDF that reads a zip file and saves it as `.parquet` file on a mounted disk.

:::note
    Fused UDFs by default run on serverless instances, so their local storage changes at every run. To keep data persistent across runs we use shared mounted storage across all the instances of your team
:::

`fused.file_path()` returns the mount path of any file we'd like to create

```python showLineNumbers
import fused

datestr='2023_03_29'

url=f'https://coast.noaa.gov/htdata/CMSP/AISDataHandler/{datestr[:4]}/AIS_{datestr}.zip'
path=fused.file_path(f'/AIS/{datestr[:7]}/{datestr[-2:]}')
```

We would then get:

```bash
'/tmp/fused/AIS/2023_03/29'
```

AIS datapoint from NOAA's platform are available per day but we'll aggregate them per month to make it simpler to manage:

```
- /tmp/fused/AIS/2024_01/
    - 01.parquet
    - 02.parquet
    ...
- /tmp/fused/AIS/2024_02/
    - 01.parquet
    - 02.parquet
...
```

### 3.2 - Writing a UDF to open each AIS dataset

The rest of the logic is to open each file, read it as a CSV and write it to parquet.

Read more about how to [write UDFs here](/core-concepts/write/)

```python showLineNumbers
@fused.udf()
def read_ais_from_noaa_udf(datestr='2023_03_29', overwrite=False):
    import os
    import requests
    import io
    import zipfile
    import pandas as pd
    import s3fs
    # This is the specific URL where daily AIS data is available
    url=f'https://coast.noaa.gov/htdata/CMSP/AISDataHandler/{datestr[:4]}/AIS_{datestr}.zip'
    # This is our local mount file path, 
    path=fused.file_path(f'/AIS/{datestr[:7]}/')
    daily_ais_parquet = f'{path}/{datestr[-2:]}.parquet'

    # Skipping any existing files
    if os.path.exists(daily_ais_parquet) and not overwrite:
        print('exist')
        return pd.DataFrame({'status':['exist']})

    # Download ZIP file to mounted disk
    r=requests.get(url)
    if r.status_code == 200:
        with zipfile.ZipFile(io.BytesIO(r.content), 'r') as z:
            with z.open(f'AIS_{datestr}.csv') as f:
                df = pd.read_csv(f)
                # MMSI is the unique identifier of each boat. This is a simple clean up for demonstration
                df['MMSI'] = df['MMSI'].astype(str)
                df.to_parquet(daily_ais_parquet)      
        return pd.DataFrame({'status':['Done']})
    else:
        return pd.DataFrame({'status':[f'read_error_{r.status_code}']})
```

{/* Running this UDF 1 time to try it out */}

### 3.3 - Run this UDF over a year of AIS data

_🚧 Under construction_

### 3.4 - Ingest 1 year of AIS data into a geo-partitioned format

_🚧 Under construction_

## 4. Retrieving Sentinel 1 images

_🚧 Under construction_

## 5. Simple boat detection in Sentinel 1 radar images

_🚧 Under construction_

## 6. Retrieving AIS data for our time of Interest

_🚧 Under construction_

## 7. Merging the 2 datasets together

_🚧 Under construction_

## Limitations & Next steps

{/* 
Talk about how this analysis is quite simple, but a good starting point 
Next steps:
- 
*/}

_🚧 Under construction_