---
sidebar_label: Fonctions de haut niveau
title: Fonctions de haut niveau
toc_max_heading_level: 4
---

## @fused.udf

```python
udf(
    fn: Optional[Callable] = None,
    *,
    name: Optional[str] = None,
    cache_max_age: Optional[str] = None,
    instance_type: Optional[str] = None,
    default_parameters: Optional[Dict[str, Any]] = None,
    headers: Optional[Sequence[Union[str, Header]]] = None,
    **kwargs: dict[str, Any]
) -> Callable[..., Udf]
```

Un d√©corateur qui transforme une fonction en un Fused UDF.

**Param√®tres :**

- **name** (<code>Optional[str]</code>) ‚Äì Le nom de l'objet UDF. Par d√©faut, il prend le nom de la fonction.

- **cache_max_age** (<code>Optional[str]</code>) ‚Äì L'√¢ge maximum lors du retour d'un r√©sultat du cache.

- **instance_type** (<code>Optional[str]</code>) ‚Äì Le type d'instance par d√©faut √† utiliser pour l'ex√©cution √† distance
  ('realtime' ou 'batch').

- **default_parameters** (<code>Optional\[Dict[str, Any]\]</code>) ‚Äì Param√®tres √† int√©grer dans l'objet UDF, s√©par√©ment de la liste des arguments
  de la fonction. Par d√©faut, None pour des param√®tres vides.

- **headers** (<code>Optional\[Sequence\[Union[str, Header]\]\]</code>) ‚Äì Une liste de fichiers √† inclure en tant que modules lors de l'ex√©cution de l'UDF. Par exemple,
  en sp√©cifiant `headers=['my_header.py']`, √† l'int√©rieur de la fonction UDF, il peut √™tre
  r√©f√©renc√© comme :

  ```py
  import my_header
  my_header.my_function()
  ```

  Par d√©faut, None pour aucun en-t√™te.

**Retourne :**

- <code>[Callable](#typing.Callable)\[..., [Udf](#fused.models.udf.Udf)\]</code> ‚Äì Un appelable qui repr√©sente l'UDF transform√©. Cet appelable peut √™tre utilis√©
- <code>[Callable](#typing.Callable)\[..., [Udf](#fused.models.udf.Udf)\]</code> ‚Äì dans des flux de travail GeoPandas pour appliquer l'op√©ration d√©finie sur des donn√©es g√©ospatiales.

**Exemples :**

Pour cr√©er un UDF simple qui appelle une fonction utilitaire pour calculer l'aire des g√©om√©tries dans un GeoDataFrame :

```py
@fused.udf
def udf(bbox, table_path="s3://fused-asset/infra/building_msft_us"):
    ...
    gdf = table_to_tile(bbox, table=table_path)
    return gdf
```

---

## @fused.cache

```python
cache(
    func: Callable[..., Any] | None = None,
    cache_max_age: str | int = DEFAULT_CACHE_MAX_AGE,
    cache_folder_path: str = "tmp",
    concurrent_lock_timeout: str | int = 120,
    cache_reset: bool | None = None,
    cache_storage: StorageStr | None = None,
    cache_key_exclude: Iterable[str] = None,
    cache_verbose: bool | None = None,
    **kwargs: Any
) -> Callable[..., Any]
```

D√©corateur pour mettre en cache la valeur de retour d'une fonction.

Cette fonction sert de d√©corateur qui peut √™tre appliqu√© √† n'importe quelle fonction
pour mettre en cache ses valeurs de retour. Le comportement de cache peut √™tre personnalis√© via
des arguments de mots-cl√©s.

**Param√®tres :**

- **func** (<code>Callable</code>) ‚Äì La fonction √† d√©corer. Si None, cela
  retourne un d√©corateur partiel avec les arguments de mots-cl√©s pass√©s.
- **cache_max_age** (<code>str | int</code>) ‚Äì Une cha√Æne avec un composant num√©rique et des unit√©s. Les unit√©s prises en charge sont secondes (s), minutes (m), heures (h), et
  jours (d) (par exemple "48h", "10s", etc.).
- **cache_folder_path** (<code>str</code>) ‚Äì Dossier √† ajouter au r√©pertoire de cache configur√©.
- **concurrent_lock_timeout** (<code>str | int</code>) ‚Äì Temps maximum en secondes pour que les appels concurrents suivants attendent qu'un appel concurrent pr√©c√©dent termine son ex√©cution et √©crive le fichier de cache.
- **cache_reset** (<code>bool | None</code>) ‚Äì Ignorer `cache_max_age` et √©craser le r√©sultat mis en cache.
- **cache_storage** (<code>StorageStr | None</code>) ‚Äì D√©finir o√π les donn√©es de cache sont stock√©es. Les valeurs prises en charge sont "auto", "mount" et "local". Auto s√©lectionnera
  automatiquement l'emplacement de stockage d√©fini dans les options (mount si cela existe, sinon local) et
  s'assure qu'il existe et est accessible en √©criture. Mount est partag√© entre les ex√©cutions tandis que local ne sera partag√©
  que dans la m√™me ex√©cution.
- **cache_key_exclude** (<code>Iterable[str]</code>) ‚Äì Un it√©rable de noms de param√®tres √† exclure du calcul de la cl√© de cache. Utile pour
  les arguments qui n'affectent pas le r√©sultat de la fonction et pourraient provoquer une expiration de cache non intentionnelle (par exemple,
  objets de connexion √† la base de donn√©es)
- **cache_verbose** (<code>bool | None</code>) ‚Äì Imprimer un message lorsqu'un r√©sultat mis en cache est retourn√©

Retourne :
Callable: Un d√©corateur qui, lorsqu'il est appliqu√© √† une fonction, met en cache ses
valeurs de retour selon les arguments de mots-cl√©s sp√©cifi√©s.

**Exemples :**

Utilisez le d√©corateur `@cache` pour mettre en cache la valeur de retour d'une fonction dans un chemin personnalis√©.

```py
@cache(path="/tmp/custom_path/")
def expensive_function():
    # L'impl√©mentation de la fonction va ici
    return result
```

Si la sortie d'une fonction mise en cache change, par exemple si des donn√©es distantes sont modifi√©es,
elle peut √™tre r√©initialis√©e en ex√©cutant la fonction avec l'argument de mot-cl√© `cache_reset`. Ensuite,
l'argument peut √™tre effac√©.

```py
@cache(path="/tmp/custom_path/", cache_reset=True)
def expensive_function():
    # L'impl√©mentation de la fonction va ici
    return result
```

---

## fused.load

```python
load(
    url_or_udf: Union[str, Path],
    /,
    *,
    cache_key: Any = None,
    import_globals: bool = True,
) -> AnyBaseUdf
```

Charge un UDF √† partir de diverses sources, y compris les URL GitHub,
et un identifiant sp√©cifique √† la plateforme Fused.

Cette fonction prend en charge le chargement des UDF √† partir d'une URL de d√©p√¥t GitHub, ou d'un Fused
identifiant sp√©cifique √† la plateforme compos√© d'un e-mail et du nom de l'UDF. Elle d√©termine intelligemment
le type de source en fonction du format de l'entr√©e et r√©cup√®re l'UDF
en cons√©quence.

**Param√®tres :**

- **url_or_udf** (<code>Union[str, Path]</code>) ‚Äì Une cha√Æne repr√©sentant l'emplacement de l'UDF, ou le code brut de l'UDF.
  L'emplacement peut √™tre une URL GitHub commen√ßant par "https://github.com",
  un identifiant sp√©cifique √† la plateforme Fused au format "email/udf_name",
  ou un chemin de fichier local pointant vers un fichier Python.
- **cache_key** (<code>Any</code>) ‚Äì Une cl√© optionnelle utilis√©e pour mettre en cache l'UDF charg√©. Si fournie, la fonction
  tentera de charger l'UDF √† partir du cache en utilisant cette cl√© avant d'essayer de
  le charger √† partir de la source sp√©cifi√©e. Par d√©faut, None, indiquant aucune mise en cache.
- **import_globals** (<code>bool</code>) ‚Äì Exposer les globals d√©finis dans le contexte de l'UDF en tant qu'attributs sur l'objet UDF (par d√©faut True).
  Cela n√©cessite d'ex√©cuter le code de l'UDF. Pour configurer ce comportement globalement, utilisez `fused.options.never_import`.

**Retourne :**

- **AnyBaseUdf** (<code>[AnyBaseUdf](#fused.models.udf.AnyBaseUdf)</code>) ‚Äì Une instance de l'UDF charg√©.

**L√®ve :**

- <code>[ValueError](#ValueError)</code> ‚Äì Si l'URL ou le format de l'identifiant sp√©cifique √† la plateforme Fused est incorrect ou
  ne peut pas √™tre analys√©.
- <code>[Exception](#Exception)</code> ‚Äì Pour des erreurs li√©es √† des probl√®mes de r√©seau, des permissions d'acc√®s aux fichiers, ou d'autres
  erreurs impr√©vues lors du processus de chargement.

**Exemples :**

Chargez un UDF √† partir d'une URL GitHub :

```py
udf = fused.load("https://github.com/fusedio/udfs/tree/main/public/REM_with_HyRiver/")
```

Chargez un UDF en utilisant un identifiant sp√©cifique √† la plateforme Fused :

```py
udf = fused.load("username@fused.io/REM_with_HyRiver")
```

---

## fused.run

```python
run(
    udf: Union[str, None, UdfJobStepConfig, Udf, UdfAccessToken] = None,
    *,
    x: Optional[int] = None,
    y: Optional[int] = None,
    z: Optional[int] = None,
    sync: bool = True,
    engine: Optional[Literal["remote", "local"]] = None,
    instance_type: Optional[InstanceType] = None,
    type: Optional[Literal["tile", "file"]] = None,
    max_retry: int = 0,
    cache_max_age: Optional[str] = None,
    cache: bool = True,
    parameters: Optional[Dict[str, Any]] = None,
    _return_response: Optional[bool] = False,
    _ignore_unknown_arguments: bool = False,
    _cancel_callback: Callable[[], bool] | None = None,
    **kw_parameters: Callable[[], bool] | None
) -> Union[
    ResultType,
    Coroutine[ResultType, None, None],
    UdfEvaluationResult,
    Coroutine[UdfEvaluationResult, None, None],
]
```

Ex√©cute une fonction d√©finie par l'utilisateur (UDF) avec diverses options d'ex√©cution et d'entr√©e.

Cette fonction prend en charge l'ex√©cution des UDF dans diff√©rents environnements (local ou distant),
avec diff√©rents types d'entr√©es (coordonn√©es de tuiles, bo√Ætes g√©ographiques, etc.), et
permet une ex√©cution √† la fois synchrone et asynchrone. Elle d√©termine dynamiquement le chemin d'ex√©cution
en fonction des param√®tres fournis.

**Param√®tres :**

- **udf** (<code>str, Udf or UdfJobStepConfig</code>) ‚Äì l'UDF √† ex√©cuter.
  L'UDF peut √™tre sp√©cifi√© de plusieurs mani√®res :
  - Une cha√Æne repr√©sentant un nom UDF ou un jeton partag√© UDF.
  - Un objet UDF.
  - Un objet UdfJobStepConfig pour une configuration d'ex√©cution d√©taill√©e.
- **x, y, z** (<code>int</code>) ‚Äì Coordonn√©es de tuiles pour l'ex√©cution UDF bas√©e sur des tuiles.
- **sync** (<code>bool</code>) ‚Äì Si True, ex√©cute l'UDF de mani√®re synchrone. Si False, ex√©cute de mani√®re asynchrone.
- **engine** (<code>Optional\[Literal['remote', 'local']\]</code>) ‚Äì Le moteur d'ex√©cution √† utiliser ('remote' ou 'local').
- **instance_type** (<code>Optional[InstanceType]</code>) ‚Äì Le type d'instance √† utiliser pour l'ex√©cution √† distance ('realtime',
  ou 'small', 'medium', 'large' ou l'un des types d'instance sur liste blanche).
  Si non sp√©cifi√©, obtient la valeur par d√©faut de l'UDF (si sp√©cifi√© dans le
  d√©corateur `@fused.udf()`, et l'UDF n'est pas ex√©cut√© en tant que jeton partag√©),
  sinon par d√©faut √† 'realtime'.
- **type** (<code>Optional\[Literal['tile', 'file']\]</code>) ‚Äì Le type d'ex√©cution UDF ('tile' ou 'file').
- **max_retry** (<code>int</code>) ‚Äì Le nombre maximum de tentatives √† effectuer si l'UDF √©choue.
  Par d√©faut, ne r√©essaie pas.
- **cache_max_age** (<code>Optional[str]</code>) ‚Äì L'√¢ge maximum lors du retour d'un r√©sultat du cache.
  Les unit√©s prises en charge sont secondes (s), minutes (m), heures (h), et jours (d) (par exemple ‚Äú48h‚Äù, ‚Äú10s‚Äù, etc.).
  La valeur par d√©faut est `None`, donc une ex√©cution UDF avec `fused.run()` suivra `cache_max_age` d√©fini dans `@fused.udf()` √† moins que cette valeur ne soit modifi√©e.
- **cache** (<code>bool</code>) ‚Äì D√©fini sur False comme un raccourci pour `cache_max_age='0s'` pour d√©sactiver la mise en cache.
- **verbose** ‚Äì D√©fini sur False pour supprimer toute instruction d'impression de l'UDF.
- **parameters** (<code>Optional\[Dict[str, Any]\]</code>) ‚Äì Param√®tres suppl√©mentaires √† passer √† l'UDF.
- \*\***kw_parameters** ‚Äì Param√®tres suppl√©mentaires √† passer √† l'UDF.

**L√®ve :**

- <code>[ValueError](#ValueError)</code> ‚Äì Si l'UDF n'est pas sp√©cifi√© ou est sp√©cifi√© de plus d'une mani√®re.
- <code>[TypeError](#TypeError)</code> ‚Äì Si le premier param√®tre n'est pas d'un type attendu.
- <code>[Warning](#Warning)</code> ‚Äì Divers avertissements sont √©mis pour les param√®tres ignor√©s en fonction du chemin d'ex√©cution choisi.

**Retourne :**

- <code>[Union](#typing.Union)\[[ResultType](#fused._run.ResultType), [Coroutine](#typing.Coroutine)\[[ResultType](#fused._run.ResultType), None, None\], [UdfEvaluationResult](#fused.models.udf._eval_result.UdfEvaluationResult), [Coroutine](#typing.Coroutine)\[[UdfEvaluationResult](#fused.models.udf._eval_result.UdfEvaluationResult), None, None\]\]</code> ‚Äì Le r√©sultat de l'ex√©cution de l'UDF, qui varie en fonction de l'UDF et du chemin d'ex√©cution.

**Exemples :**

Ex√©cutez un UDF enregistr√© dans le syst√®me Fused :

```py
fused.run("username@fused.io/my_udf_name")
```

Ex√©cutez un UDF enregistr√© sur GitHub :

```py
loaded_udf = fused.load("https://github.com/fusedio/udfs/tree/main/public/Building_Tile_Example")
fused.run(loaded_udf, bbox=bbox)
```

Ex√©cutez un UDF enregistr√© dans un r√©pertoire local :

```py
loaded_udf = fused.load("/Users/local/dir/Building_Tile_Example")
fused.run(loaded_udf, bbox=bbox)
```

<details class="note" open>
<summary>Note</summary>
Cette fonction d√©termine dynamiquement le chemin d'ex√©cution et les param√®tres en fonction des entr√©es.
Elle est con√ßue pour √™tre flexible et prendre en charge divers sc√©narios d'ex√©cution UDF.
</details>

---

## fused.submit

```python
submit(
    udf: AnyBaseUdf | FunctionType | str,
    arg_list: AnyBaseUdf | FunctionType | str,
    /,
    *,
    engine: Literal["remote", "local"] | None = "remote",
    instance_type: InstanceType | None = None,
    max_workers: int | None = None,
    n_processes_per_worker: int | None = None,
    max_retry: int = 2,
    debug_mode: bool = False,
    collect: bool = True,
    execution_type: ExecutionType = "thread_pool",
    cache_max_age: str | None = None,
    cache: bool = True,
    ignore_exceptions: bool = False,
    flatten: bool = True,
    _before_run: float | None = None,
    _before_submit: float | None = 0.01,
    **kwargs: float | None,
) -> Union[BaseJobPool, ResultType, pd.DataFrame]
```

Ex√©cute une fonction d√©finie par l'utilisateur (UDF) plusieurs fois pour une liste de param√®tres d'entr√©e, et retourne imm√©diatement un objet JobPool "paresseux" permettant
d'inspecter les travaux et d'attendre les r√©sultats.

Chaque ex√©cution UDF individuelle sera mise en cache suivant la logique de mise en cache standard comme avec `fused.run()`
et le `cache_max_age` sp√©cifi√©. De plus, lorsque `collect=True` (par d√©faut), les r√©sultats collect√©s
sont mis en cache localement pour la dur√©e de `cache_max_age` ou 12h par d√©faut.

Voir `fused.run` pour plus de d√©tails sur l'ex√©cution de l'UDF.

**Param√®tres :**

- **udf** (<code>AnyBaseUdf | FunctionType | str</code>) ‚Äì l'UDF √† ex√©cuter.
  Voir `fused.run` pour plus de d√©tails sur la fa√ßon de sp√©cifier l'UDF.
- **arg_list** ‚Äì une liste de param√®tres d'entr√©e pour l'UDF. Peut √™tre sp√©cifi√© comme :
  - une liste de valeurs pour param√©trer un seul param√®tre, c'est-√†-dire
    le premier param√®tre de l'UDF
  - une liste de dictionnaires pour param√©trer plusieurs param√®tres
  - Un DataFrame pour param√©trer plusieurs param√®tres o√π chaque
    ligne est un ensemble de param√®tres
- **engine** (<code>Literal['remote', 'local'] | None</code>) ‚Äì Le moteur d'ex√©cution √† utiliser. Par d√©faut, 'remote'.
- **instance_type** (<code>InstanceType | None</code>) ‚Äì Le type d'instance √† utiliser pour l'ex√©cution √† distance ('realtime',
  ou 'small', 'medium', 'large' ou l'un des types d'instance sur liste blanche).
  Si non sp√©cifi√©, obtient la valeur par d√©faut de l'UDF (si sp√©cifi√© dans le
  d√©corateur `@fused.udf()`, et l'UDF n'est pas ex√©cut√© en tant que jeton partag√©),
  sinon par d√©faut √† 'realtime'.
- **max_workers** (<code>int | None</code>) ‚Äì Le nombre maximum de travailleurs √† utiliser. Par d√©faut, 32 pour
  le moteur en temps r√©el (avec un maximum de 1024), et 1 pour d'autres instances de lot
  (avec un maximum de 5).
- **n_processes_per_worker** (<code>int | None</code>) ‚Äì Le nombre de processus √† utiliser par travailleur.
  Toujours 1 pour le moteur en temps r√©el, mais par d√©faut au nombre de c≈ìurs
  pour les moteurs de lot. Sp√©cifiez ce mot-cl√© pour r√©duire le nombre de processus.
- **max_retry** (<code>int</code>) ‚Äì Le nombre maximum de tentatives pour les travaux √©chou√©s. Par d√©faut, 2.
- **debug_mode** (<code>bool</code>) ‚Äì Si True, ex√©cute uniquement le premier √©l√©ment dans arg_list directement en utilisant
  `fused.run()`, utile pour le d√©bogage de l'ex√©cution de l'UDF. La valeur par d√©faut est False.
- **collect** (<code>bool</code>) ‚Äì Si True, attend que tous les travaux soient termin√©s et retourne le DataFrame collect√©
  contenant les r√©sultats. Si False, retourne un objet JobPool, qui est non-bloquant
  et vous permet d'inspecter les r√©sultats individuels et les journaux.
  La valeur par d√©faut est True.
- **execution_type** (<code>ExecutionType</code>) ‚Äì Le type de traitement √† utiliser. Soit "thread_pool" (par d√©faut) pour
  la concurrence bas√©e sur ThreadPoolExecutor ou "async_loop" pour la concurrence bas√©e sur asyncio.
- **cache_max_age** (<code>str | None</code>) ‚Äì L'√¢ge maximum lors du retour d'un r√©sultat du cache.
  Les unit√©s prises en charge sont secondes (s), minutes (m), heures (h), et jours (d)
  (par exemple "48h", "10s", etc.).
  La valeur par d√©faut est `None`, donc une ex√©cution UDF avec `fused.run()` suivra
  `cache_max_age` d√©fini dans `@fused.udf()` √† moins que cette valeur ne soit modifi√©e.
- **cache** (<code>bool</code>) ‚Äì D√©fini sur False comme un raccourci pour `cache_max_age='0s'` pour d√©sactiver la mise en cache.
- **ignore_exceptions** (<code>bool</code>) ‚Äì D√©fini sur True pour ignorer les exceptions lors de la collecte des r√©sultats.
  Les ex√©cutions qui entra√Ænent des exceptions seront silencieusement ignor√©es. La valeur par d√©faut est False.
- **flatten** (<code>bool</code>) ‚Äì D√©fini sur True pour recevoir un DataFrame de r√©sultats, sans imbrication d'une
  colonne `results`, lors de la collecte des r√©sultats. Lorsque False, les r√©sultats seront imbriqu√©s
  dans une colonne `results`. Si l'UDF ne retourne pas un DataFrame (par exemple, une cha√Æne
  √† la place), les r√©sultats seront imbriqu√©s dans une colonne `results` ind√©pendamment de ce param√®tre.
  La valeur par d√©faut est True.
- \*\***kwargs** ‚Äì Arguments de mots-cl√©s suppl√©mentaires (constants) √† passer √† l'UDF.

**Retourne :**

- <code>[Union](#typing.Union)\[[BaseJobPool](#fused._submit.BaseJobPool), [ResultType](#fused._run.ResultType), [DataFrame](#pandas.DataFrame)\]</code> ‚Äì JobPool, AsyncJobPool, ou DataFrame selon les param√®tres execution_type et collect

**Exemples :**

Ex√©cutez un UDF plusieurs fois pour les valeurs de 0 √† 9 pass√©es comme le premier
argument positionnel de l'UDF :

```py
df = fused.submit("username@fused.io/my_udf_name", range(10))
```

Utilisation du type de lot asynchrone :

```py
df = fused.submit(udf, range(10), execution_type="async_loop")
```

√ätre explicite sur le nom du param√®tre :

```py
df = fused.submit(udf, [dict(n=i) for i in range(10)])
```

Obtenez le pool des t√¢ches en cours :

```py
pool = fused.submit(udf, [dict(n=i) for i in range(10)], collect=False)
```

---

## fused.download

```python
download(url: str, file_path: str, storage: StorageStr = 'auto') -> str
```

T√©l√©charge un fichier.

Peut √™tre appel√© depuis plusieurs processus avec les m√™mes entr√©es pour obtenir le m√™me r√©sultat.

Fused ex√©cute les UDF de haut en bas chaque fois que le code change. Cela signifie que les objets dans l'UDF sont recr√©√©s √† chaque fois, ce qui peut ralentir un UDF qui t√©l√©charge des fichiers depuis un serveur distant.

üí° Les fichiers t√©l√©charg√©s sont √©crits dans un volume mont√© partag√© entre tous les UDF dans une organisation. Cela signifie qu'un fichier t√©l√©charg√© par un UDF peut √™tre lu par d'autres UDF.

Fused aborde la latence du t√©l√©chargement de fichiers avec la fonction utilitaire de t√©l√©chargement. Elle stocke les fichiers dans le syst√®me de fichiers mont√© afin qu'ils ne soient t√©l√©charg√©s que la premi√®re fois.

üí° √âtant donn√© qu'un UDF de tuile ex√©cute plusieurs morceaux en parall√®le, la fonction de t√©l√©chargement d√©finit un verrou de signal pendant la premi√®re tentative de t√©l√©chargement, pour s'assurer que le t√©l√©chargement se produit une seule fois.

**Param√®tres :**

- **url** (<code>str</code>) ‚Äì L'URL √† t√©l√©charger.
- **file_path** (<code>str</code>) ‚Äì Le chemin local o√π enregistrer le fichier.
- **storage** (<code>StorageStr</code>) ‚Äì D√©finir o√π les donn√©es de cache sont stock√©es. Les valeurs prises en charge sont "auto", "mount" et "local". Auto s√©lectionnera
  automatiquement l'emplacement de stockage d√©fini dans les options (mount si cela existe, sinon local) et
  s'assure qu'il existe et est accessible en √©criture. Mount est partag√© entre les ex√©cutions tandis que local ne sera partag√©
  que dans la m√™me ex√©cution.

**Retourne :**

- <code>[str](#str)</code> ‚Äì La fonction t√©l√©charge le fichier uniquement lors de la premi√®re ex√©cution, et retourne le chemin du fichier.

**Exemples :**

```python
@fused.udf
def geodataframe_from_geojson():
    import geopandas as gpd
    url = "s3://sample_bucket/my_geojson.zip"
    path = fused.core.download(url, "tmp/my_geojson.zip")
    gdf = gpd.read_file(path)
    return gdf
```

---

## fused.ingest

```python
ingest(
    input: str | Path | Sequence[str | Path] | gpd.GeoDataFrame,
    output: str | None = None,
    *,
    output_metadata: str | None = None,
    schema: Schema | None = None,
    file_suffix: str | None = None,
    load_columns: Sequence[str] | None = None,
    remove_cols: Sequence[str] | None = None,
    explode_geometries: bool = False,
    drop_out_of_bounds: bool | None = None,
    partitioning_method: Literal["area", "length", "coords", "rows"] = "rows",
    partitioning_maximum_per_file: int | float | None = None,
    partitioning_maximum_per_chunk: int | float | None = None,
    partitioning_max_width_ratio: int | float = 2,
    partitioning_max_height_ratio: int | float = 2,
    partitioning_force_utm: Literal["file", "chunk", None] = "chunk",
    partitioning_split_method: Literal["mean", "median"] = "mean",
    subdivide_method: Literal["area", None] = None,
    subdivide_start: float | None = None,
    subdivide_stop: float | None = None,
    split_identical_centroids: bool = True,
    target_num_chunks: int = 500,
    lonlat_cols: tuple[str, str] | None = None,
    partitioning_schema_input: str | pd.DataFrame | None = None,
    gdal_config: GDALOpenConfig | dict[str, Any] | None = None,
    overwrite: bool = False,
    as_udf: bool = False
) -> GeospatialPartitionJobStepConfig
```

Incorpore un ensemble de donn√©es dans le format partitionn√© Fused.

**Param√®tres :**

- **input** (<code>str | Path | Sequence[str | Path] | gpd.GeoDataFrame</code>) ‚Äì Un GeoPandas `GeoDataFrame` ou un chemin vers un ou plusieurs fichiers sur S3 √† ing√©rer. Les fichiers peuvent √™tre Parquet ou un autre format de donn√©es g√©ographiques.

- **output** (<code>str | None</code>) ‚Äì Emplacement sur S3 pour √©crire la table `main`.

- **output_metadata** (<code>str | None</code>) ‚Äì Emplacement sur S3 pour √©crire la table `fused`.

- **schema** (<code>Schema | None</code>) ‚Äì Sch√©ma des donn√©es √† ing√©rer. Ceci est optionnel et sera d√©duit des donn√©es si non fourni.

- **file_suffix** (<code>str | None</code>) ‚Äì filtre les fichiers utilis√©s pour l'ingestion. Si `input` est un r√©pertoire sur S3, tous les fichiers sous ce r√©pertoire seront list√©s et utilis√©s pour l'ingestion. Si `file_suffix` n'est pas None, il sera utilis√© pour filtrer les chemins en v√©rifiant les caract√®res de fin de chaque nom de fichier. Par exemple, passez `file_suffix=".geojson"` pour inclure uniquement les fichiers GeoJSON √† l'int√©rieur du r√©pertoire.

- **load_columns** (<code>Sequence[str] | None</code>) ‚Äì Lire uniquement cet ensemble de colonnes lors de l'ingestion de jeux de donn√©es g√©ospatiaux. Par d√©faut, toutes les colonnes.

- **remove_cols** (<code>Sequence[str] | None</code>) ‚Äì Les colonnes nomm√©es √† supprimer lors de l'ingestion de jeux de donn√©es g√©ospatiaux. Par d√©faut, aucune colonne n'est supprim√©e.

- **explode_geometries** (<code>bool</code>) ‚Äì Que faut-il d√©baller les g√©om√©tries multiparties en g√©om√©tries simples lors de l'ingestion de jeux de donn√©es g√©ospatiaux, en sauvegardant chaque partie comme sa propre ligne. Par d√©faut, `False`.

- **drop_out_of_bounds** (<code>bool | None</code>) ‚Äì Que faut-il supprimer les g√©om√©tries en dehors des limites WGS84 attendues. Par d√©faut, True.

- **partitioning_method** (<code>Literal['area', 'length', 'coords', 'rows']</code>) ‚Äì La m√©thode √† utiliser pour regrouper les lignes en partitions. Par d√©faut, `"rows"`.

  - `"area"` : Construire des partitions o√π toutes contiennent une aire totale maximale parmi les g√©om√©tries.
  - `"length"` : Construire des partitions o√π toutes contiennent une longueur totale maximale parmi les g√©om√©tries.
  - `"coords"` : Construire des partitions o√π toutes contiennent un nombre total maximal de coordonn√©es parmi les g√©om√©tries.
  - `"rows"` : Construire des partitions o√π toutes contiennent un nombre maximal de lignes.

- **partitioning_maximum_per_file** (<code>int | float | None</code>) ‚Äì Valeur maximale pour `partitioning_method` √† utiliser par fichier. Si `None`, par d√©faut √† _1/10√®me_ de la valeur totale de `partitioning_method`. Donc si la valeur est `None` et `partitioning_method` est `"area"`, alors chaque fichier n'aura pas plus de 1/10√®me de la surface totale de toutes les g√©om√©tries. Par d√©faut, `None`.

- **partitioning_maximum_per_chunk** (<code>int | float | None</code>) ‚Äì Valeur maximale pour `partitioning_method` √† utiliser par morceau. Si `None`, par d√©faut √† _1/100√®me_ de la valeur totale de `partitioning_method`. Donc si la valeur est `None` et `partitioning_method` est `"area"`, alors chaque fichier n'aura pas plus de 1/100√®me de la surface totale de toutes les g√©om√©tries. Par d√©faut, `None`.

- **partitioning_max_width_ratio** (<code>int | float</code>) ‚Äì Le ratio maximum de largeur √† hauteur de chaque partition √† utiliser dans le processus d'ingestion. Donc par exemple, si la valeur est `2`, alors si la largeur divis√©e par la hauteur est sup√©rieure √† `2`, la bo√Æte sera divis√©e en deux le long de l'axe horizontal. Par d√©faut, `2`.

- **partitioning_max_height_ratio** (<code>int | float</code>) ‚Äì Le ratio maximum de hauteur √† largeur de chaque partition √† utiliser dans le processus d'ingestion. Donc par exemple, si la valeur est `2`, alors si la hauteur divis√©e par la largeur est sup√©rieure √† `2`, la bo√Æte sera divis√©e en deux le long de l'axe vertical. Par d√©faut, `2`.

- **partitioning_force_utm** (<code>Literal['file', 'chunk', None]</code>) ‚Äì Que faut-il forcer le partitionnement dans les zones UTM. Si d√©fini sur `"file"`, cela garantira que le centro√Øde de toutes les g√©om√©tries par _fichier_ est contenu dans la m√™me zone UTM. Si d√©fini sur `"chunk"`, cela garantira que le centro√Øde de toutes les g√©om√©tries par _morceau_ est contenu dans la m√™me zone UTM. Si d√©fini sur `None`, alors aucun partitionnement bas√© sur UTM ne sera effectu√©. Par d√©faut, "chunk".

- **partitioning_split_method** (<code>Literal['mean', 'median']</code>) ‚Äì Comment diviser une partition en enfants. Par d√©faut, `"mean"` (cela peut changer √† l'avenir).

  - `"mean"` : Diviser chaque axe selon la moyenne des valeurs des centro√Ødes.
  - `"median"` : Diviser chaque axe selon la m√©diane des valeurs des centro√Ødes.

- **subdivide_method** (<code>Literal['area', None]</code>) ‚Äì La m√©thode √† utiliser pour subdiviser de grandes g√©om√©tries en plusieurs lignes. Actuellement, la seule option est `"area"`, o√π les g√©om√©tries seront subdivis√©es en fonction de leur aire (en degr√©s WGS84).

- **subdivide_start** (<code>float | None</code>) ‚Äì La valeur au-dessus de laquelle les g√©om√©tries seront subdivis√©es en parties plus petites, selon `subdivide_method`.

- **subdivide_stop** (<code>float | None</code>) ‚Äì La valeur en dessous de laquelle les g√©om√©tries ne seront pas subdivis√©es en parties plus petites, selon `subdivide_method`. Recommand√© d'√™tre √©gal √† subdivide_start. Si `None`, les g√©om√©tries seront subdivis√©es jusqu'√† une profondeur de r√©cursion de 100 ou jusqu'√† ce que la g√©om√©trie subdivis√©e soit rectangulaire.

- **split_identical_centroids** (<code>bool</code>) ‚Äì Si `True`, doit diviser une partition qui a
  des centro√Ødes identiques (comme si toutes les g√©om√©tries dans la partition sont les
  m√™mes) s'il y a plus de telles lignes que d√©fini dans "partitioning_maximum_per_file" et
  "partitioning_maximum_per_chunk".

- **target_num_chunks** (<code>int</code>) ‚Äì L'objectif pour le nombre de fichiers si `partitioning_maximum_per_file` est None. Notez que ce nombre est seulement un _objectif_ et le nombre r√©el de fichiers g√©n√©r√©s peut √™tre sup√©rieur ou inf√©rieur √† ce nombre, selon la distribution spatiale des donn√©es elles-m√™mes.
  Par d√©faut, 500, valeur par d√©faut approximative √† utiliser dans la plupart des cas.

- **lonlat_cols** (<code>tuple[str, str] | None</code>) ‚Äì Noms des colonnes de longitude, latitude pour construire des g√©om√©tries de points.

  Si vos colonnes de points sont nomm√©es `"x"` et `"y"`, alors passez :

  ```py
  fused.ingest(
      ...,
      lonlat_cols=("x", "y")
  )
  ```

  Cela ne s'applique qu'√† la lecture √† partir de fichiers Parquet. Pour la lecture √† partir de fichiers CSV, passez des options √† `gdal_config`.

- **gdal_config** (<code>GDALOpenConfig | dict[str, Any] | None</code>) ‚Äì Options de configuration √† passer √† GDAL pour la fa√ßon de lire ces fichiers. Pour tous les fichiers autres que les fichiers Parquet, Fused utilise GDAL comme √©tape dans le processus d'ingestion. Pour certaines entr√©es, comme les fichiers CSV ou les shapefiles compress√©s, vous devrez peut-√™tre passer certains param√®tres √† GDAL pour lui indiquer comment ouvrir vos fichiers.

  Cette configuration est cens√©e √™tre un dictionnaire avec jusqu'√† deux cl√©s :

  - `layer`: `str`. D√©finir la couche du fichier d'entr√©e que vous souhaitez lire lorsque la source contient plusieurs couches, comme dans GeoPackage.
  - `open_options`: `Dict[str, str]`. Passer des paires cl√©-valeur avec les options d'ouverture GDAL. Celles-ci sont d√©finies sur la page de chaque pilote dans la documentation GDAL. Par exemple, le [pilote CSV](https://gdal.org/drivers/vector/csv.html) d√©finit [ces options d'ouverture](https://gdal.org/drivers/vector/csv.html#open-options) que vous pouvez passer.

  Par exemple, si vous ing√©rez un fichier CSV avec deux colonnes
  `"longitude"` et `"latitude"` d√©signant les informations de coordonn√©es, passez

  ```py
  fused.ingest(
      ...,
      gdal_config={
          "open_options": {
              "X_POSSIBLE_NAMES": "longitude",
              "Y_POSSIBLE_NAMES": "latitude",
          }
      }
  )
  ```

- **overwrite** (<code>bool</code>) ‚Äì Si True, √©craser le r√©pertoire de sortie s'il existe d√©j√†
  (en supprimant d'abord tout le contenu existant du r√©pertoire, c'est-√†-dire qu'il
  n'√©crase pas seulement les fichiers en conflit).
  Par d√©faut, False.

- **as_udf** (<code>bool</code>) ‚Äì Retourner le flux de travail d'ingestion en tant qu'UDF qui peut √™tre ex√©cut√© en utilisant
  `fused.run()`. Les fichiers locaux ou les objets python pass√©s √† `input` ou
  `partitioning_schema_input` sont toujours t√©l√©charg√©s sur S3 d'abord afin que
  ceux-ci soient disponibles lors de l'ex√©cution de l'UDF √† distance. Par d√©faut, False.

**Retourne :**

- <code>[GeospatialPartitionJobStepConfig](#fused.models.api.GeospatialPartitionJobStepConfig)</code> ‚Äì Objet de configuration d√©crivant le processus d'ingestion. Appelez `.execute` sur cet objet pour d√©marrer un travail.

**Exemples :**

Par exemple, pour ing√©rer le jeu de donn√©es du recensement de Californie pour l'ann√©e 2022 :

```py
job = fused.ingest(
    input="https://www2.census.gov/geo/tiger/TIGER_RD18/STATE/06_CALIFORNIA/06/tl_rd22_06_bg.zip",
    output="s3://fused-sample/census/ca_bg_2022/main/",
    output_metadata="s3://fused-sample/census/ca_bg_2022/fused/",
    explode_geometries=True,
    partitioning_maximum_per_file=2000,
    partitioning_maximum_per_chunk=200,
).execute()
```

---


#### `job.run_batch`

```python showLineNumbers
def run_batch(output_table: Optional[str] = ...,
    instance_type: Optional[WHITELISTED_INSTANCE_TYPES] = None,
    *,
    region: str | None = None,
    disk_size_gb: int | None = None,
    additional_env: List[str] | None = None,
    image_name: Optional[str] = None,
    ignore_no_udf: bool = False,
    ignore_no_output: bool = False,
    validate_imports: Optional[bool] = None,
    validate_inputs: bool = True,
    overwrite: Optional[bool] = None) -> RunResponse
```

Commence l'ex√©cution du travail d'ingestion en appelant `run_batch` sur l'objet de travail.

**Arguments** :

- `output_table` - Le nom de la table √† √©crire. Par d√©faut, None.
- `instance_type` - Le type d'instance AWS EC2 √† utiliser pour le travail. Les cha√Ænes acceptables sont `m5.large`, `m5.xlarge`, `m5.2xlarge`, `m5.4xlarge`, `m5.8xlarge`, `m5.12xlarge`, `m5.16xlarge`, `r5.large`, `r5.xlarge`, `r5.2xlarge`, `r5.4xlarge`, `r5.8xlarge`, `r5.12xlarge`, ou `r5.16xlarge`. Par d√©faut, None.
- `region` - La r√©gion AWS dans laquelle ex√©cuter. Par d√©faut, None.
- `disk_size_gb` - La taille du disque √† sp√©cifier pour le travail. Par d√©faut, None.
- `additional_env` - Toute variable d'environnement suppl√©mentaire √† passer dans le travail. Par d√©faut, None.
- `image_name` - Nom d'image personnalis√© √† ex√©cuter. Par d√©faut, None pour l'image par d√©faut.
- `ignore_no_udf` - Ignorer les erreurs de validation concernant la non-sp√©cification d'un UDF. Par d√©faut, False.
- `ignore_no_output` - Ignorer les erreurs de validation concernant la non-sp√©cification d'un emplacement de sortie. Par d√©faut, False.

#### Surveiller et g√©rer le travail

L'appel √† `run_batch` retourne un objet `RunResponse` avec des m√©thodes d'aide.

```python showLineNumbers
# D√©clarer le travail d'ingestion
job = fused.ingest(
  input="https://www2.census.gov/geo/tiger/TIGER_RD18/STATE/06_CALIFORNIA/06/tl_rd22_06_bg.zip",
  output="s3://fused-sample/census/ca_bg_2022/main/"
)

# D√©marrer le travail d'ingestion
job_id = job.run_batch()
```

R√©cup√©rez le statut du travail.

```python showLineNumbers
job_id.get_status()
```

R√©cup√©rez et imprimez les journaux du travail.

```python showLineNumbers
job_id.print_logs()
```

D√©terminez le temps d'ex√©cution du travail.

```python showLineNumbers
job_id.get_exec_time()
```

Imprimez continuellement les journaux du travail.

```python showLineNumbers
job_id.tail_logs()
```

Annulez le travail.

```python showLineNumbers
job_id.cancel()
```

---

#### `job.run_remote`

Alias de `job.run_batch` pour la compatibilit√© ascendante. Voir `job.run_batch` ci-dessus
pour les d√©tails.

---

## fused.ingest_nongeospatial

```python
ingest_nongeospatial(
    input: str | Path | Sequence[str, Path] | pd.DataFrame | gpd.GeoDataFrame,
    output: str | None = None,
    *,
    output_metadata: str | None = None,
    partition_col: str | None = None,
    partitioning_maximum_per_file: int = 2500000,
    partitioning_maximum_per_chunk: int = 65000
) -> NonGeospatialPartitionJobStepConfig
```

Incorpore un ensemble de donn√©es dans le format partitionn√© Fused.

**Param√®tres :**

- **input** (<code>str | Path | Sequence[str, Path] | pd.DataFrame | gpd.GeoDataFrame</code>) ‚Äì Un GeoPandas `GeoDataFrame` ou un chemin vers un ou plusieurs fichiers sur S3 √† ing√©rer. Les fichiers peuvent √™tre Parquet ou un autre format de donn√©es g√©ographiques.
- **output** (<code>str | None</code>) ‚Äì Emplacement sur S3 pour √©crire la table `main`.
- **output_metadata** (<code>str | None</code>) ‚Äì Emplacement sur S3 pour √©crire la table `fused`.
- **partition_col** (<code>str | None</code>) ‚Äì Partition le long de cette colonne pour les ensembles de donn√©es non g√©ospatiaux.
- **partitioning_maximum_per_file** (<code>int</code>) ‚Äì Nombre maximum d'√©l√©ments √† stocker dans un seul fichier. Par d√©faut, 2 500 000.
- **partitioning_maximum_per_chunk** (<code>int</code>) ‚Äì Nombre maximum d'√©l√©ments √† stocker dans un seul fichier. Par d√©faut, 65 000.

**Retourne :**

- <code>[NonGeospatialPartitionJobStepConfig](#fused.models.api.NonGeospatialPartitionJobStepConfig)</code> ‚Äì Objet de configuration d√©crivant le processus d'ingestion. Appelez `.execute` sur cet objet pour d√©marrer un travail.

**Exemples :**

```py
job = fused.ingest_nongeospatial(
    input=gdf,
    output="s3://sample-bucket/file.parquet",
).execute()
```

---

## fused.file_path

```python
file_path(
    file_path: str, mkdir: bool = True, storage: StorageStr = "auto"
) -> str
```

Cr√©e un r√©pertoire dans un r√©pertoire temporaire pr√©d√©fini.

Cela donne aux utilisateurs la possibilit√© de g√©rer des r√©pertoires lors de l'ex√©cution d'un UDF.
Il prend un chemin de fichier relatif, cr√©e la structure de r√©pertoire correspondante,
et retourne son chemin absolu.

Ceci est utile pour les UDF qui stockent temporairement des r√©sultats interm√©diaires sous forme de fichiers,
comme lors de l'√©criture de fichiers interm√©diaires sur disque lors du traitement de grands ensembles de donn√©es.
`file_path` s'assure que les r√©pertoires n√©cessaires existent.
Le r√©pertoire est conserv√© pendant 12h.

**Param√®tres :**

- **file_path** (<code>str</code>) ‚Äì Le chemin de fichier relatif √† localiser.
- **mkdir** (<code>bool</code>) ‚Äì Si True, cr√©e le r√©pertoire s'il n'existe pas d√©j√†. Par d√©faut, True.
- **storage** (<code>StorageStr</code>) ‚Äì D√©finir o√π les donn√©es de cache sont stock√©es. Les valeurs prises en charge sont "auto", "mount" et "local". Auto s√©lectionnera
  automatiquement l'emplacement de stockage d√©fini dans les options (mount si cela existe, sinon local) et
  s'assure qu'il existe et est accessible en √©criture. Mount est partag√© entre les ex√©cutions tandis que local ne sera partag√©
  que dans la m√™me ex√©cution.

**Retourne :**

- <code>[str](#str)</code> ‚Äì Le chemin de fichier localis√©.

---

## fused.get_chunks_metadata

```python
get_chunks_metadata(url: str) -> gpd.GeoDataFrame
```

Retourne un GeoDataFrame avec chaque morceau dans la table comme une ligne.

**Param√®tres :**

- **url** (<code>str</code>) ‚Äì URL de la table.

---

## fused.get_chunk_from_table

```python
get_chunk_from_table(
    url: str,
    file_id: Union[str, int, None],
    chunk_id: Optional[int],
    *,
    columns: Optional[Iterable[str]] = None
) -> gpd.GeoDataFrame
```

Retourne un morceau d'une table et des coordonn√©es de morceau.

Cela peut √™tre appel√© avec file_id et chunk_id de `get_chunks_metadata`.

**Param√®tres :**

- **url** (<code>str</code>) ‚Äì URL de la table.
- **file_id** (<code>Union[str, int, None]</code>) ‚Äì ID de fichier √† lire.
- **chunk_id** (<code>Optional[int]</code>) ‚Äì ID de morceau √† lire.
- **columns** (<code>Optional\[Iterable[str]\]</code>) ‚Äì Lire uniquement les colonnes sp√©cifi√©es.

---