---
slug: ai-for-web-scraping
title: "Extraction de données structurées à partir de pages web"
---

Ce tutoriel démontre comment utiliser les Fused User Defined Functions ([UDFs](/core-concepts/write/)) pour extraire des données structurées à partir de pages web. Nous allons construire un ensemble de données d'écoles publiques d'une zone géographique spécifique en utilisant trois approches différentes d'extraction.

## Introduction

Imaginez que vous devez compiler une liste complète d'écoles publiques pour une zone spécifique. Une recherche rapide sur Google nous mène au site [Top Ranked Public Schools](https://www.publicschoolreview.com/top-ranked-public-schools). Ce site contient plusieurs sous-pages pour différents emplacements comme [Connecticut](https://www.publicschoolreview.com/top-ranked-public-schools/connecticut) ou [New York](https://www.publicschoolreview.com/top-ranked-public-schools/new-york).

Chaque page affiche initialement un nombre limité d'écoles, nécessitant que les utilisateurs cliquent sur "voir plus" pour charger des résultats supplémentaires. Notre objectif est d'extraire des données de manière programmatique à partir de ces pages et de générer des fichiers CSV pour n'importe quel emplacement sans navigation manuelle.

import SeeMoreImg from '@site/static/img/tutorials/data-science-ai/see_more.png';

<div style={{textAlign: 'center'}}>
<img src={SeeMoreImg} alt="Fichier" style={{}} />
</div>

## Méthode 1 : Extraction de page individuelle

Lorsque vous connaissez l'URL exacte de la page et si elle contient du contenu paginé, utilisez le [scrapegraph web scraper UDF](https://www.fused.io/workbench/udf/catalog/scrapegraph_web_scraper-0a121078-1b03-4c62-ba23-274ffb4c7568) pour extraire des données structurées à partir de pages uniques.

### Paramètres

| Paramètre | Type | Description |
|-----------|------|-------------|
| **url** | string | L'URL de la page web cible à extraire |
| **query** | string | Description en langage naturel des données à extraire |
| **output_schema** | dict (optionnel) | Structure attendue des données de sortie |
| **pagination_pages** | int (optionnel) | Nombre de pages paginées à extraire |
| **scroll_pages** | int (optionnel) | Nombre d'actions de défilement pour les pages à défilement infini |

### Exemple d'utilisation

**Utilisation du SDK Python :**

```python
import fused

df = fused.run(
    "fsh_3A1QcdR5kJEwmDSkYxc934",
    url="https://www.publicschoolreview.com/top-ranked-public-schools/connecticut/tab/all/num/1",
    query="Extraire les noms des écoles, les classements et les adresses",
    pagination_pages=2
)
df.head()
```

**Sortie :**

import DfOutput from '@site/static/img/tutorials/data-science-ai/df_out_1.png';

<div style={{textAlign: 'center'}}>
<img src={DfOutput} alt="Fichier" style={{}} />
</div>

## Méthode 2 : Extraction par lots de plusieurs pages

Lorsque vous devez extraire des données de plusieurs URL connues simultanément, utilisez le [scrapegraph multi scraper UDF](https://www.fused.io/workbench/udf/catalog/scrapegraph_multi_scraper-8aaafa63-3888-4f12-8d31-6e3f9098b2ae). Cet UDF crée un schéma de sortie unifié sur toutes les pages et les traite en parallèle à l'aide des appels [fused.submit](/python-sdk/top-level-functions/#fusedsubmit).

### Paramètres

| Paramètre | Type | Description |
|-----------|------|-------------|
| **urls** | list | Liste des URL de pages web à extraire par lots |
| **query** | string | Description en langage naturel des données à extraire |
| **pagination_pages** | int (optionnel) | Nombre de pages paginées à extraire par URL |
| **scroll_pages** | int (optionnel) | Nombre d'actions de défilement pour les pages à défilement infini |

### Exemple d'utilisation

**Utilisation du SDK Python :**

```python
import fused

df = fused.run(
    "fsh_5WETmX04oWgWtSCxwv1ZNr",
    urls=[
        "https://www.publicschoolreview.com/top-ranked-public-schools/new-york/tab/all/num/1",
        "https://www.publicschoolreview.com/top-ranked-public-schools/new-york/tab/all/num/3",
    ],
    query="Extraire les noms des écoles, les plages de notes et les adresses pour toutes les écoles de NYC"
)
df.head()
```

**Sortie :**

import DfOutput2 from '@site/static/img/tutorials/data-science-ai/df_out_2.png';

<div style={{textAlign: 'center'}}>
<img src={DfOutput2} alt="Fichier" style={{}} />
</div>

## Méthode 3 : Exploration et extraction intelligentes

Lorsque vous ne connaissez que le domaine de premier niveau mais pas les URL de page spécifiques, utilisez le [firecrawl search UDF](https://www.fused.io/workbench/udf/catalog/firecrawl_search-43935d03-7e82-4173-baa8-2f0e63d0c473) pour découvrir et extraire automatiquement les pages pertinentes. Cet UDF explore le site web, identifie les pages les plus pertinentes en fonction de vos critères de recherche et extrait les données demandées.

### Paramètres

| Paramètre | Type | Description |
|-----------|------|-------------|
| **url** | string | L'URL de base à explorer et à rechercher |
| **search_prompt** | string | Description en langage naturel du contenu à trouver |
| **extraction_prompt** | string | Description en langage naturel des données à extraire |

### Exemple d'utilisation

**Utilisation du SDK Python :**

```python
import fused

df = fused.run(
    "fsh_6mpu2dqoEBc1W80GjhZLSM",
    url="https://www.publicschoolreview.com",
    search_prompt="meilleures écoles publiques dans le connecticut",
    extraction_prompt="Extraire les noms des écoles, les plages de notes et les adresses"
)
df.head()
```

**Sortie :**

import DfOutput3 from '@site/static/img/tutorials/data-science-ai/df_out_3.png';

<div style={{textAlign: 'center'}}>
<img src={DfOutput3} alt="Fichier" style={{}} />
</div>

## Utilisation des points de terminaison HTTPS API

Pour l'intégration dans des systèmes externes ou des flux de travail automatisés, vous pouvez [générer des points de terminaison HTTPS partagés](/core-concepts/run-udfs/run-small-udfs/#https-requests) pour ces UDFs. Cela vous permet de récupérer des données au format CSV à l'aide de simples requêtes HTTPS.

### Points de terminaison disponibles

**Extracteur de page individuelle :**
```bash
curl "https://www.fused.io/server/v1/realtime-shared/fsh_3A1QcdR5kJEwmDSkYxc934/run/file?format=csv"
```

**Extracteur de plusieurs pages :**
```bash
curl "https://www.fused.io/server/v1/realtime-shared/fsh_5WETmX04oWgWtSCxwv1ZNr/run/file?format=csv"
```

**Explorateur intelligent :**
```bash
curl "https://www.fused.io/server/v1/realtime-shared/fsh_6mpu2dqoEBc1W80GjhZLSM/run/file?format=csv"
```

## Personnalisez-le

Ce sont des UDFs communautaires que vous pouvez forker et personnaliser selon vos besoins. Il vous suffit de cliquer sur "Faire une copie à modifier" dans le Fused Workbench pour créer votre propre copie.

**Configuration de l'API requise** : Vous devrez configurer vos propres clés API pour les services tiers en tant que [fused secrets](/workbench/preferences/#secrets-management)

## Voir aussi

- Transformer [n'importe quel UDF en API](/tutorials/engineering-etl/#turn-your-data-into-an-api)
- Permettre à quiconque de communiquer avec vos données [via les serveurs MCP](/tutorials/Analytics%20&%20Dashboard/let-anyone-talk-to-your-data/)
- [Exécuter des tâches en parallèle](/core-concepts/run-udfs/run-small-udfs/#running-jobs-in-parallel-fusedsubmit) avec `fused.submit()`

*Remarque : Ces fonctionnalités d'extraction de données sont actuellement en développement actif et vous pourriez rencontrer des problèmes occasionnels.*